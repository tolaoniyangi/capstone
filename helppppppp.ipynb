{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point, Polygon\n",
    "import matplotlib.pyplot as plt\n",
    "from fiona.crs import from_epsg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib, json, requests \n",
    "import geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyleaflet import Map, GeoData, GeoJSON, basemaps, basemap_to_tiles, Icon, Circle, Marker, LayerGroup, WidgetControl\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Button \n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need this to stop numpy from returning truncated arrays \n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting basic map\n",
    "center = (40.7210907,-73.9877836)\n",
    "basemap = basemap_to_tiles(basemaps.CartoDB.Positron)\n",
    "\n",
    "m = Map(layers=(basemap, ), center=center, zoom=15, min_zoom = 7, max_zoom = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_location():       \n",
    "    global gdf, lat, lon\n",
    "    \n",
    "    lat = str(markerlocation[0])\n",
    "    lon = str(markerlocation[1])\n",
    "    \n",
    "    df2 = pd.DataFrame(markerlocation)\n",
    "    df=df2.transpose()\n",
    "    df.columns=['Latitude','Longitude']\n",
    "\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.Longitude, df.Latitude), crs='epsg:4326')\n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "draggable=False\n",
    "marker_opacity=1\n",
    "icon = Icon(icon_url='icon.png', icon_size=[15, 15])\n",
    "\n",
    "marker = Marker(location=center, draggable=draggable, icon=icon, opacity=marker_opacity)\n",
    "\n",
    "markerlocation = marker.location \n",
    "\n",
    "layer_group = LayerGroup(layers=(marker, ))\n",
    "m.add_layer(layer_group)\n",
    "   \n",
    "def update_marker(**kwargs):\n",
    "    \n",
    "    if kwargs.get('type') == 'click':\n",
    "        layer_group.clear_layers();\n",
    "        \n",
    "        marker = Marker(location=kwargs.get('coordinates'), draggable=draggable, icon=icon, opacity=marker_opacity, options=['rise_on_hover'])  \n",
    "        \n",
    "        global markerlocation\n",
    "        markerlocation = marker.location \n",
    "        \n",
    "        layer_group.add_layer(marker)\n",
    "    \n",
    "        draw_update_buffer(**kwargs)\n",
    "    \n",
    "m.on_interaction(update_marker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_update_buffer(**kwargs):     \n",
    "    m.on_interaction(update_marker)\n",
    "    extract_location()\n",
    "    \n",
    "    global half_mi\n",
    "    half_mi=gdf.copy()\n",
    "    half_mi['geometry'] = half_mi.geometry.buffer(.004,  cap_style=1, join_style=1)\n",
    "\n",
    "    map_extent = gdf.copy()\n",
    "    map_extent['geometry'] = map_extent.buffer(1,  cap_style=1, join_style=1)\n",
    "\n",
    "    diff = gpd.overlay(map_extent, half_mi, how='difference')\n",
    "    \n",
    "    half_mi_difference = GeoData(geo_dataframe = diff,\n",
    "                       style={'color': \"black\", \\\n",
    "                              'fillColor': \"#000000\", \\\n",
    "                              'fillOpacity': .2, \\\n",
    "                              'opacity': 1, \\\n",
    "                              'weight': 2},\n",
    "                       name = \"Test\", crs='epsg:4326')\n",
    "\n",
    "    layer_group.add_layer(half_mi_difference) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received 12 entries, 12 total\n",
      "Received 1 entries, 13 total\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>GEOID</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>TRACT</th>\n",
       "      <th>NAME</th>\n",
       "      <th>OBJECTID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((-73.98986 40.72053, -73.98962 40.720...</td>\n",
       "      <td>36061003001</td>\n",
       "      <td>36</td>\n",
       "      <td>061</td>\n",
       "      <td>003001</td>\n",
       "      <td>Census Tract 30.01</td>\n",
       "      <td>10843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((-73.99326 40.72235, -73.99352 40.721...</td>\n",
       "      <td>36061003601</td>\n",
       "      <td>36</td>\n",
       "      <td>061</td>\n",
       "      <td>003601</td>\n",
       "      <td>Census Tract 36.01</td>\n",
       "      <td>10846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON ((-73.99155 40.72709, -73.99179 40.726...</td>\n",
       "      <td>36061003800</td>\n",
       "      <td>36</td>\n",
       "      <td>061</td>\n",
       "      <td>003800</td>\n",
       "      <td>Census Tract 38</td>\n",
       "      <td>10847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON ((-73.98788 40.71741, -73.98837 40.716...</td>\n",
       "      <td>36061001402</td>\n",
       "      <td>36</td>\n",
       "      <td>061</td>\n",
       "      <td>001402</td>\n",
       "      <td>Census Tract 14.02</td>\n",
       "      <td>26519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>POLYGON ((-73.98845 40.72328, -73.98864 40.722...</td>\n",
       "      <td>36061003002</td>\n",
       "      <td>36</td>\n",
       "      <td>061</td>\n",
       "      <td>003002</td>\n",
       "      <td>Census Tract 30.02</td>\n",
       "      <td>40986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>POLYGON ((-73.98454 40.71639, -73.98501 40.715...</td>\n",
       "      <td>36061001200</td>\n",
       "      <td>36</td>\n",
       "      <td>061</td>\n",
       "      <td>001200</td>\n",
       "      <td>Census Tract 12</td>\n",
       "      <td>45321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>POLYGON ((-73.99233 40.72491, -73.99260 40.724...</td>\n",
       "      <td>36061003602</td>\n",
       "      <td>36</td>\n",
       "      <td>061</td>\n",
       "      <td>003602</td>\n",
       "      <td>Census Tract 36.02</td>\n",
       "      <td>52962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>POLYGON ((-73.98705 40.72520, -73.98750 40.724...</td>\n",
       "      <td>36061003200</td>\n",
       "      <td>36</td>\n",
       "      <td>061</td>\n",
       "      <td>003200</td>\n",
       "      <td>Census Tract 32</td>\n",
       "      <td>56775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>POLYGON ((-73.99750 40.71407, -73.99744 40.714...</td>\n",
       "      <td>36061001600</td>\n",
       "      <td>36</td>\n",
       "      <td>061</td>\n",
       "      <td>001600</td>\n",
       "      <td>Census Tract 16</td>\n",
       "      <td>71680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>POLYGON ((-73.99442 40.71939, -73.99481 40.718...</td>\n",
       "      <td>36061001800</td>\n",
       "      <td>36</td>\n",
       "      <td>061</td>\n",
       "      <td>001800</td>\n",
       "      <td>Census Tract 18</td>\n",
       "      <td>71681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>POLYGON ((-73.98448 40.72024, -73.98507 40.719...</td>\n",
       "      <td>36061002201</td>\n",
       "      <td>36</td>\n",
       "      <td>061</td>\n",
       "      <td>002201</td>\n",
       "      <td>Census Tract 22.01</td>\n",
       "      <td>71962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>POLYGON ((-73.98344 40.72202, -73.98382 40.721...</td>\n",
       "      <td>36061002202</td>\n",
       "      <td>36</td>\n",
       "      <td>061</td>\n",
       "      <td>002202</td>\n",
       "      <td>Census Tract 22.02</td>\n",
       "      <td>71963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>POLYGON ((-73.98344 40.72202, -73.98382 40.721...</td>\n",
       "      <td>36061002202</td>\n",
       "      <td>36</td>\n",
       "      <td>061</td>\n",
       "      <td>002202</td>\n",
       "      <td>Census Tract 22.02</td>\n",
       "      <td>71963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             geometry        GEOID STATE  \\\n",
       "0   POLYGON ((-73.98986 40.72053, -73.98962 40.720...  36061003001    36   \n",
       "1   POLYGON ((-73.99326 40.72235, -73.99352 40.721...  36061003601    36   \n",
       "2   POLYGON ((-73.99155 40.72709, -73.99179 40.726...  36061003800    36   \n",
       "3   POLYGON ((-73.98788 40.71741, -73.98837 40.716...  36061001402    36   \n",
       "4   POLYGON ((-73.98845 40.72328, -73.98864 40.722...  36061003002    36   \n",
       "5   POLYGON ((-73.98454 40.71639, -73.98501 40.715...  36061001200    36   \n",
       "6   POLYGON ((-73.99233 40.72491, -73.99260 40.724...  36061003602    36   \n",
       "7   POLYGON ((-73.98705 40.72520, -73.98750 40.724...  36061003200    36   \n",
       "8   POLYGON ((-73.99750 40.71407, -73.99744 40.714...  36061001600    36   \n",
       "9   POLYGON ((-73.99442 40.71939, -73.99481 40.718...  36061001800    36   \n",
       "10  POLYGON ((-73.98448 40.72024, -73.98507 40.719...  36061002201    36   \n",
       "11  POLYGON ((-73.98344 40.72202, -73.98382 40.721...  36061002202    36   \n",
       "12  POLYGON ((-73.98344 40.72202, -73.98382 40.721...  36061002202    36   \n",
       "\n",
       "   COUNTY   TRACT                NAME  OBJECTID  \n",
       "0     061  003001  Census Tract 30.01     10843  \n",
       "1     061  003601  Census Tract 36.01     10846  \n",
       "2     061  003800     Census Tract 38     10847  \n",
       "3     061  001402  Census Tract 14.02     26519  \n",
       "4     061  003002  Census Tract 30.02     40986  \n",
       "5     061  001200     Census Tract 12     45321  \n",
       "6     061  003602  Census Tract 36.02     52962  \n",
       "7     061  003200     Census Tract 32     56775  \n",
       "8     061  001600     Census Tract 16     71680  \n",
       "9     061  001800     Census Tract 18     71681  \n",
       "10    061  002201  Census Tract 22.01     71962  \n",
       "11    061  002202  Census Tract 22.02     71963  \n",
       "12    061  002202  Census Tract 22.02     71963  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def import_censustracts():\n",
    "    draw_update_buffer()\n",
    "    \n",
    "    bounding_box = half_mi.envelope\n",
    "    df = gpd.GeoDataFrame(gpd.GeoSeries(bounding_box), columns=['geometry'])\n",
    "    minx, miny, maxx, maxy = df.geometry.total_bounds\n",
    "    bounds = minx, miny, maxx, maxy\n",
    "\n",
    "    # census tracts link\n",
    "    endpoint = 'https://tigerweb.geo.census.gov/arcgis/rest/services/TIGERweb/Tracts_Blocks/MapServer/4/query'\n",
    "    s = requests.session()\n",
    "    s.params = {\n",
    "        'geometry': str(bounds),\n",
    "        'geometryType': 'esriGeometryEnvelope',\n",
    "        'inSR': 4326,\n",
    "        'spatialRel': 'esriSpatialRelIntersects',\n",
    "        'outFields': 'GEOID,STATE,COUNTY,TRACT,NAME,STGEOMETRY,OBJECTID',\n",
    "        'returnGeometry': True,\n",
    "        'f': 'geojson',        \n",
    "    }\n",
    "    start = 0\n",
    "    done = False\n",
    "    features = []\n",
    "    crs = None\n",
    "    while not done:\n",
    "        r = s.get(endpoint, params={\n",
    "            'resultOffset': start,\n",
    "            'resultRecordCount': 32,\n",
    "        })\n",
    "        censusgeo = geojson.loads(r.text)\n",
    "        newfeats = censusgeo.__geo_interface__['features']\n",
    "        if newfeats:\n",
    "            features.extend(newfeats)\n",
    "            crs=censusgeo.__geo_interface__['crs']\n",
    "            start += len(newfeats)\n",
    "            print(\"Received\", len(newfeats), \"entries,\", start, \"total\")\n",
    "        else:\n",
    "            done = True\n",
    "    \n",
    "    global tracts\n",
    "    tracts = gpd.GeoDataFrame.from_features(features, crs=crs)\n",
    "    return tracts\n",
    "\n",
    "import_censustracts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_acs():  \n",
    "    state = tracts[\"STATE\"].unique().tolist()\n",
    "    state = ', '.join(map(str, state)).replace(\" \", \"\")\n",
    "\n",
    "    tract = tracts[\"TRACT\"].unique().tolist()\n",
    "    tract = ', '.join(map(str, tract)).replace(\" \", \"\") \n",
    "\n",
    "    county = tracts[\"COUNTY\"].unique().tolist()\n",
    "    county = ', '.join(map(str, county)).replace(\" \", \"\") \n",
    "\n",
    "    api_key = '9330dc4bf086a84f19fb412bb15f232507301de6'\n",
    "    acs_url = f'https://api.census.gov/data/2018/acs/acs5/subject/'\n",
    "    \n",
    "    global acs_variables\n",
    "    acs_variables_initial = 'S1901_C04_001E,S1901_C01_001E,S1603_C02_002E,S1603_C02_003E,S1603_C02_004E,S1601_C01_005E,S1601_C01_006E,S1601_C01_007E,S1601_C01_009E,S1601_C01_010E,S1601_C01_011E,S1601_C01_013E,S1601_C01_014E,S1601_C01_015E,S1601_C01_017E,S1601_C01_018E,S1601_C01_019E,S1901_C01_002E,S1901_C01_003E,S1901_C01_004E,S1901_C01_005E,S1901_C01_006E,S1901_C01_007E,S1901_C01_008E,S1901_C01_009E,S1901_C01_010E,S1901_C01_011E,S1901_C04_002E,S1901_C04_003E,S1901_C04_004E,S1901_C04_005E,S1901_C04_006E,S1901_C04_007E,S1901_C04_008E,S1901_C04_009E,S1901_C04_010E,S1901_C04_011E'\n",
    "    acs_variables_additional = 'S1501_C01_002E,S1501_C01_004E,S1501_C01_003E,S1501_C01_005E,S1501_C01_017E,S1501_C01_018E,S1501_C01_020E,S1501_C01_021E,S1501_C01_023E,S1501_C01_024E,S1501_C01_025E,S1501_C01_026E,S1501_C03_002E,S1501_C03_003E,S1501_C03_004E,S1501_C03_005E,S1501_C03_017E,S1501_C03_018E,S1501_C03_020E,S1501_C03_021E,S1501_C03_023E,S1501_C03_024E,S1501_C03_026E,S1501_C03_027E,S1501_C05_002E,S1501_C05_003E,S1501_C05_004E,S1501_C05_005E,S1501_C05_017E,S1501_C05_018E,S1501_C05_020E,S1501_C05_021E,S1501_C05_023E,S1501_C05_024E,S1501_C05_026E,S1501_C05_027E,S1401_C01_030E,S1401_C01_032E,S1401_C01_034E'\n",
    "    acs_variables = acs_variables_initial + \",\" + acs_variables_additional\n",
    "    \n",
    "    get_acs_initial = f'{acs_url}?&get={acs_variables_initial}&for=tract:{tract}&in=state:{state}%20county:{county}&key={api_key}'\n",
    "    get_acs_additional = f'{acs_url}?&get={acs_variables_additional}&for=tract:{tract}&in=state:{state}%20county:{county}&key={api_key}'\n",
    "\n",
    "    data_acs_initial=requests.get(get_acs_initial).json()\n",
    "    data_acs_additional=requests.get(get_acs_additional).json()\n",
    "    \n",
    "    global acs\n",
    "    acs_initial=pd.DataFrame(data_acs_initial[1:], columns=data_acs_initial[0])\n",
    "    acs_additional=pd.DataFrame(data_acs_additional[1:], columns=data_acs_additional[0])\n",
    "\n",
    "    acs=pd.merge(acs_initial, acs_additional, on='tract', how='left')\n",
    "\n",
    "download_acs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#any null rows?\n",
    "test = acs.columns[acs.isnull().any()]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acs = acs.drop(['S0901_C01_033E', 'S0901_C01_034E', 'S0902_C01_003E', 'S0902_C01_004E','S0902_C01_005E'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_combine_census_and_geographic_data():\n",
    "    global acs_site_sum, acs_site\n",
    "    tracts[\"area\"]=tracts.area\n",
    "    acs_tracts = pd.merge(tracts, acs, left_on='TRACT', right_on='tract', how='left')\n",
    "    \n",
    "    acs_site = gpd.overlay(half_mi, acs_tracts, how='intersection')\n",
    "    acs_site[\"area_clipped\"]=acs_site.area \n",
    "    acs_site[\"ratio\"] = acs_site[\"area_clipped\"]/acs_site[\"area\"]\n",
    "    \n",
    "    cols = acs_variables.split(\",\")\n",
    "    acs_site[cols] = acs_site[cols].apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "    \n",
    "    # if 'area_clipped' not in cols:\n",
    "    #     cols.append(\"area_clipped\")\n",
    "    \n",
    "    temp_df = acs_site[cols]    \n",
    "    temp_df = temp_df.mul(acs_site.ratio, 0)\n",
    "    acs_site.update(temp_df)\n",
    "\n",
    "    acs_site_sum = pd.DataFrame(acs_site[cols].sum())\n",
    "\n",
    "    acs_site_sum.reset_index(inplace=True)\n",
    "    acs_site_sum.columns = ['variables', 'sum_in_area']\n",
    "    \n",
    "clean_combine_census_and_geographic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age_group</th>\n",
       "      <th>variable_group</th>\n",
       "      <th>variables</th>\n",
       "      <th>variable_name</th>\n",
       "      <th>variable_description</th>\n",
       "      <th>ages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Both</td>\n",
       "      <td>5 to 17 years</td>\n",
       "      <td>Language Spoken At Home</td>\n",
       "      <td>S1603_C02_002E</td>\n",
       "      <td>Speak Only English at Home</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Both</td>\n",
       "      <td>18 to 64 years</td>\n",
       "      <td>Language Spoken At Home</td>\n",
       "      <td>S1603_C02_003E</td>\n",
       "      <td>Speak Only English at Home</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18, 19, 20, 21, 22, 23, 24, 25,26, 27, 28, 29,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Both</td>\n",
       "      <td>65 years and over</td>\n",
       "      <td>Language Spoken At Home</td>\n",
       "      <td>S1603_C02_004E</td>\n",
       "      <td>Speak Only English at Home</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Both</td>\n",
       "      <td>5 to 17 years</td>\n",
       "      <td>Language Spoken At Home</td>\n",
       "      <td>S1603_C04_002E</td>\n",
       "      <td>Speak a Language other than English at Home</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Both</td>\n",
       "      <td>18 to 64 years</td>\n",
       "      <td>Language Spoken At Home</td>\n",
       "      <td>S1603_C04_003E</td>\n",
       "      <td>Speak a Language other than English at Home</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18, 19, 20, 21, 22, 23, 24, 25,26, 27, 28, 29,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>Female</td>\n",
       "      <td>65 years and over</td>\n",
       "      <td>Educational Attainment</td>\n",
       "      <td>S1501_C05_026E</td>\n",
       "      <td>High school graduate or higher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>Female</td>\n",
       "      <td>65 years and over</td>\n",
       "      <td>Educational Attainment</td>\n",
       "      <td>S1501_C05_027E</td>\n",
       "      <td>Bachelor's degree or higher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>Both</td>\n",
       "      <td>18 to 24 years</td>\n",
       "      <td>School Enrollment</td>\n",
       "      <td>S1401_C01_030E</td>\n",
       "      <td>Enrolled in college or graduate school</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18, 19, 20, 21, 22, 23, 24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>Male</td>\n",
       "      <td>18 to 24 years</td>\n",
       "      <td>School Enrollment</td>\n",
       "      <td>S1401_C01_032E</td>\n",
       "      <td>Enrolled in college or graduate school</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18, 19, 20, 21, 22, 23, 24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>Female</td>\n",
       "      <td>18 to 24 years</td>\n",
       "      <td>School Enrollment</td>\n",
       "      <td>S1401_C01_034E</td>\n",
       "      <td>Enrolled in college or graduate school</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18, 19, 20, 21, 22, 23, 24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sex           age_group           variable_group       variables  \\\n",
       "0     Both       5 to 17 years  Language Spoken At Home  S1603_C02_002E   \n",
       "1     Both      18 to 64 years  Language Spoken At Home  S1603_C02_003E   \n",
       "2     Both  65 years and over   Language Spoken At Home  S1603_C02_004E   \n",
       "3     Both       5 to 17 years  Language Spoken At Home  S1603_C04_002E   \n",
       "4     Both      18 to 64 years  Language Spoken At Home  S1603_C04_003E   \n",
       "..     ...                 ...                      ...             ...   \n",
       "72  Female   65 years and over   Educational Attainment  S1501_C05_026E   \n",
       "73  Female   65 years and over   Educational Attainment  S1501_C05_027E   \n",
       "74    Both      18 to 24 years        School Enrollment  S1401_C01_030E   \n",
       "75    Male      18 to 24 years        School Enrollment  S1401_C01_032E   \n",
       "76  Female      18 to 24 years        School Enrollment  S1401_C01_034E   \n",
       "\n",
       "                                  variable_name variable_description  \\\n",
       "0                    Speak Only English at Home                  NaN   \n",
       "1                    Speak Only English at Home                  NaN   \n",
       "2                    Speak Only English at Home                  NaN   \n",
       "3   Speak a Language other than English at Home                  NaN   \n",
       "4   Speak a Language other than English at Home                  NaN   \n",
       "..                                          ...                  ...   \n",
       "72               High school graduate or higher                  NaN   \n",
       "73                  Bachelor's degree or higher                  NaN   \n",
       "74       Enrolled in college or graduate school                  NaN   \n",
       "75       Enrolled in college or graduate school                  NaN   \n",
       "76       Enrolled in college or graduate school                  NaN   \n",
       "\n",
       "                                                 ages  \n",
       "0       5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17  \n",
       "1   18, 19, 20, 21, 22, 23, 24, 25,26, 27, 28, 29,...  \n",
       "2   64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75...  \n",
       "3       5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17  \n",
       "4   18, 19, 20, 21, 22, 23, 24, 25,26, 27, 28, 29,...  \n",
       "..                                                ...  \n",
       "72  65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76...  \n",
       "73  65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76...  \n",
       "74                         18, 19, 20, 21, 22, 23, 24  \n",
       "75                         18, 19, 20, 21, 22, 23, 24  \n",
       "76                         18, 19, 20, 21, 22, 23, 24  \n",
       "\n",
       "[77 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = pd.read_csv(\"data-dictionary.csv\")\n",
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use this if i decide to add in the option to select all\n",
    "ALL = 'ALL'\n",
    "def user_options_sorted_values_plus_ALL(array):\n",
    "    unique = array.unique().tolist()\n",
    "    unique.sort()\n",
    "    unique.insert(0, ALL)\n",
    "    return unique\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_options_sorted_values(array):\n",
    "    unique = array.unique().tolist()\n",
    "    unique.sort()\n",
    "    return unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = widgets.Output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_output = widgets.Output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def user_selection():\n",
    "    \n",
    "    output.clear_output()\n",
    "    data_output.clear_output() \n",
    "    \n",
    "    global selected_age, selected_gender, selected_percentile, text_generation_button, selection_filter, variable_inputs\n",
    "#     selected_age = widgets.Dropdown(options = user_options_sorted_values(data_dict.age_group),\\\n",
    "#                                     value = \"5 to 17 Years\")\n",
    "    selected_age = widgets.BoundedIntText(min=5, max=99, value=25, step=1, description='Age:')\n",
    "    selected_gender = widgets.ToggleButtons(options = user_options_sorted_values(data_dict.sex),\\\n",
    "                                            value = \"Male\",\\\n",
    "                                            description='Sex:', \\\n",
    "                                            disabled=False, button_style='', )\n",
    "    selected_percentile = widgets.IntSlider(min=0, max=100, step=10, value=50, description='Percentile:',)\n",
    "    text_generation_button = Button(description=\"Generate Text\")\n",
    "    \n",
    "#     display(selected_age, selected_gender, selected_percentile, output)\n",
    "    \n",
    "    selected_age_str= str(selected_age.value)\n",
    "\n",
    "    selection_filter = data_dict[(data_dict.ages.str.contains(selected_age_str)) & \n",
    "                              ((data_dict.sex == selected_gender.value) |\n",
    "                              (data_dict.sex == \"Both\"))]   \n",
    "    \n",
    "    with data_output:\n",
    "            display(selection_filter)\n",
    "    \n",
    "    def selection_filtering(age_group, sex):\n",
    "        output.clear_output()\n",
    "        data_output.clear_output()\n",
    "\n",
    "        selected_age_str= str(selected_age.value)\n",
    "        \n",
    "        selection_filter = data_dict[(data_dict.ages.str.contains(selected_age_str)) & \n",
    "                                  ((data_dict.sex == selected_gender.value) |\n",
    "                                    (data_dict.sex == \"Both\"))]   \n",
    "        with data_output:\n",
    "            display(selection_filter)\n",
    "\n",
    "    def selected_age_eventhandler(change):\n",
    "        selection_filtering(change.new, selected_age.value)\n",
    "    def selected_gender_eventhandler(change):\n",
    "        selection_filtering(selected_gender.value, change.new)\n",
    "    def selected_percentile_eventhandler(change):\n",
    "        selection_filtering(selected_percentile.value, change.new)\n",
    "\n",
    "    selected_age.observe(selected_age_eventhandler, names='value')\n",
    "    selected_gender.observe(selected_gender_eventhandler, names='value')\n",
    "    selected_percentile.observe(selected_percentile_eventhandler, names='value')\n",
    "\n",
    "    list_of_variable_inputs = selection_filter[\"variables\"].values[0:]\n",
    "    variable_inputs = ', '.join(list_of_variable_inputs).replace(\" \", \"\")\n",
    "    variable_inputs = variable_inputs.split(',')\n",
    "    \n",
    "user_selection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def descriptor_generation():\n",
    "# # eventually would need to split these up into the diff bins for different types of variable groups \n",
    "#     global df\n",
    "#     df = pd.merge(acs_site_sum.loc[acs_site_sum['variables'].isin(variable_inputs)], \\\n",
    "#                    selection_filter, how=\"right\", on=\"variables\")    \n",
    "\n",
    "# # calculate percentile_input_per_variable\n",
    "#     global sum_for_percentile, percentile_input, percentile_table, percentile_table_transposed\n",
    "\n",
    "# #adding in 0 value to dataframe...to have complete table for the percentiles \n",
    "#     percentile_table = df.append({'sum_in_area' : 0, 'variables':'Baseline_Value',\\\n",
    "#                                   'variable_group':'Baseline_Group'}, ignore_index=True)\n",
    "#     percentile_table.sort_values(\"sum_in_area\", axis = 0, ascending = True, inplace = True)\n",
    "\n",
    "# #10th percentile = 0.1\n",
    "#     percentile_input = selected_percentile.value / 100\n",
    "\n",
    "# # split these up into the diff bins for different types of variable groups \n",
    "#     global language, education, household_income, school_enrollment\n",
    "\n",
    "#     for item,i in enumerate(df):       \n",
    "#         language = percentile_table[(percentile_table[\"variable_group\"].str.contains('Language|Baseline_Group'))]\n",
    "#         education = percentile_table[(percentile_table[\"variable_group\"].str.contains('Educational Attainment|Baseline_Group'))]\n",
    "#         school_enrollment = percentile_table[(percentile_table[\"variable_group\"].str.contains('School|Baseline_Group'))]\n",
    "#         household_income = percentile_table[(percentile_table[\"variable_group\"].str.contains('Income|Baseline_Group'))]\n",
    "# #       travel_time_to_work = percentile_table[(percentile_table[\"variable_group\"].str.contains('Travel Time'))]\n",
    "#         # means_of_transportation = percentile_table[(percentile_table[\"variable_group\"].str.contains('Means of Transportation'))]\n",
    "\n",
    "# # do this instead for the language tables etc \n",
    "#     global sum_for_percentile_language,sum_for_percentile_education,sum_for_percentile_school_enrollment,sum_for_percentile_household_income\n",
    "#     sum_for_percentile_language = language.sum_in_area.quantile(percentile_input).astype(int).astype(str)\n",
    "#     sum_for_percentile_education = education.sum_in_area.quantile(percentile_input).astype(int).astype(str)\n",
    "#     sum_for_percentile_school_enrollment = school_enrollment.sum_in_area.quantile(percentile_input).astype(int).astype(str)    \n",
    "#     sum_for_percentile_household_income = household_income.sum_in_area.quantile(percentile_input).astype(int).astype(str)\n",
    "    \n",
    "# #generating new transposed table with only the two fields needed : variables and sum in area.\n",
    "# #using other variables makes transposition weird\n",
    "#     global language_transposed, education_transposed, household_income_transposed, school_enrollment_transposed\n",
    "\n",
    "#     language_transposed = language.filter([\"variables\", \"sum_in_area\"]).T\n",
    "#     language_transposed.columns = language_transposed.iloc[0]\n",
    "#     language_transposed = language_transposed[1:]\n",
    "\n",
    "#     education_transposed = education.filter([\"variables\", \"sum_in_area\"]).T\n",
    "#     education_transposed.columns = education_transposed.iloc[0]\n",
    "#     education_transposed = education_transposed[1:]\n",
    "    \n",
    "#     household_income_transposed = household_income.filter([\"variables\", \"sum_in_area\"]).T\n",
    "#     household_income_transposed.columns = household_income_transposed.iloc[0]\n",
    "#     household_income_transposed = household_income_transposed[1:]    \n",
    "    \n",
    "# #     school_enrollment_transposed = school_enrollment.filter([\"variables\", \"sum_in_area\"]).T\n",
    "# #     school_enrollment_transposed.columns = school_enrollment_transposed.iloc[0]\n",
    "# #     school_enrollment_transposed = school_enrollment_transposed[1:]    \n",
    "    \n",
    "# descriptor_generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot index with vector containing NA / NaN values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-e83b10be9122>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;31m#     school_enrollment_transposed = school_enrollment_transposed[1:]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m \u001b[0mdescriptor_generation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-24-e83b10be9122>\u001b[0m in \u001b[0;36mdescriptor_generation\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mschool_enrollment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpercentile_table\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpercentile_table\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"variable_group\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'School|Baseline_Group'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mhousehold_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpercentile_table\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpercentile_table\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"variable_group\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Household|Baseline_Group'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mfamily_household_income\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpercentile_table\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpercentile_table\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"variable_description\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Family|Baseline_Group'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mnonfamily_household_income\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpercentile_table\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpercentile_table\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"variable_description\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Nonfamily|Baseline_Group'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;31m#       travel_time_to_work = percentile_table[(percentile_table[\"variable_group\"].str.contains('Travel Time'))]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2968\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2969\u001b[0m         \u001b[1;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2970\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2971\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\common.py\u001b[0m in \u001b[0;36mis_bool_indexer\u001b[1;34m(key)\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_bool_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mna_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot index with vector containing NA / NaN values"
     ]
    }
   ],
   "source": [
    "def descriptor_generation():\n",
    "# eventually would need to split these up into the diff bins for different types of variable groups \n",
    "# so we have the big dataframe with only the selected ages etc \n",
    "    global df\n",
    "#     df = pd.merge(acs_site_sum.loc[acs_site_sum['variables'].isin(variable_inputs)], \\\n",
    "#                    selection_filter, how=\"right\", on=\"variables\")    \n",
    "    df = pd.merge(acs_site_sum, \\\n",
    "                   selection_filter, how=\"inner\", on=\"variables\")    \n",
    "# calculate percentile_input_per_variable\n",
    "    global sum_for_percentile, percentile_input, percentile_table, percentile_table_transposed\n",
    "\n",
    "#adding in 0 value to dataframe...to have complete table for the percentiles \n",
    "    percentile_table = df.append({'sum_in_area' : 0, 'variables':'Baseline_Value',\\\n",
    "                                  'variable_group':'Baseline_Group'}, ignore_index=True)\n",
    "    percentile_table.sort_values(\"sum_in_area\", axis = 0, ascending = True, inplace = True)\n",
    "\n",
    "#10th percentile = 0.1\n",
    "    percentile_input = selected_percentile.value / 100\n",
    "\n",
    "# split these up into the diff bins for different types of variable groups \n",
    "    global language, education, household_type, family_household_income, nonfamily_household_income, school_enrollment\n",
    "\n",
    "    for item,i in enumerate(df):       \n",
    "        language = percentile_table[(percentile_table[\"variable_group\"].str.contains('Language|Baseline_Group'))]\n",
    "        education = percentile_table[(percentile_table[\"variable_group\"].str.contains('Educational Attainment|Baseline_Group'))]\n",
    "        school_enrollment = percentile_table[(percentile_table[\"variable_group\"].str.contains('School|Baseline_Group'))]\n",
    "#         household_type = percentile_table[(percentile_table[\"variable_group\"].str.contains('Household|Baseline_Group'))]\n",
    "        family_household_income = percentile_table[(percentile_table[\"variable_description\"].str.contains('Family|Baseline_Group'))]\n",
    "        nonfamily_household_income = percentile_table[(percentile_table[\"variable_description\"].str.contains('Nonfamily|Baseline_Group'))]\n",
    "#       travel_time_to_work = percentile_table[(percentile_table[\"variable_group\"].str.contains('Travel Time'))]\n",
    "        # means_of_transportation = percentile_table[(percentile_table[\"variable_group\"].str.contains('Means of Transportation'))]\n",
    "\n",
    "# do this instead for the language tables etc \n",
    "    global sum_for_percentile_language,sum_for_percentile_education,sum_for_percentile_school_enrollment,sum_for_percentile_household_income\n",
    "    sum_for_percentile_language = language.sum_in_area.quantile(percentile_input).astype(int).astype(str)\n",
    "    sum_for_percentile_education = education.sum_in_area.quantile(percentile_input).astype(int).astype(str)\n",
    "    sum_for_percentile_school_enrollment = school_enrollment.sum_in_area.quantile(percentile_input).astype(int).astype(str)    \n",
    "#     sum_for_percentile_household_type= household_type.sum_in_area.quantile(percentile_input).astype(int).astype(str)\n",
    "    sum_for_percentile_family_household_income = family_household_income.sum_in_area.quantile(percentile_input).astype(int).astype(str)\n",
    "    sum_for_percentile_nonfamily_household_income = nonfamily_household_income.sum_in_area.quantile(percentile_input).astype(int).astype(str)\n",
    "    \n",
    "#generating new transposed table with only the two fields needed : variables and sum in area.\n",
    "#using other variables makes transposition weird\n",
    "    global language_transposed, education_transposed, household_type_transposed, family_household_income_transposed, nonfamily_household_income_transposed, school_enrollment_transposed\n",
    "\n",
    "    language_transposed = language.filter([\"variables\", \"sum_in_area\"]).T\n",
    "    language_transposed.columns = language_transposed.iloc[0]\n",
    "    language_transposed = language_transposed[1:]\n",
    "\n",
    "    education_transposed = education.filter([\"variables\", \"sum_in_area\"]).T\n",
    "    education_transposed.columns = education_transposed.iloc[0]\n",
    "    education_transposed = education_transposed[1:]\n",
    "    \n",
    "    household_type_transposed = household_type.filter([\"variables\", \"sum_in_area\"]).T\n",
    "    household_type_transposed.columns = household_type_transposed.iloc[0]\n",
    "    household_type_transposed = household_type_transposed[1:]    \n",
    "    \n",
    "    family_household_income_transposed = family_household_income.filter([\"variables\", \"sum_in_area\"]).T\n",
    "    family_household_income_transposed.columns = family_household_income_transposed.iloc[0]\n",
    "    family_household_income_transposed = family_household_income_transposed[1:]\n",
    "    \n",
    "    nonfamily_household_income_transposed = nonfamily_household_income.filter([\"variables\", \"sum_in_area\"]).T\n",
    "    nonfamily_household_income_transposed.columns = nonfamily_household_income_transposed.iloc[0]\n",
    "    nonfamily_household_income_transposed = nonfamily_household_income_transposed[1:]\n",
    "    \n",
    "#     school_enrollment_transposed = school_enrollment.filter([\"variables\", \"sum_in_area\"]).T\n",
    "#     school_enrollment_transposed.columns = school_enrollment_transposed.iloc[0]\n",
    "#     school_enrollment_transposed = school_enrollment_transposed[1:]    \n",
    "    \n",
    "descriptor_generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ranges2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-507fba3ebe57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# family_household_income_with_ranges\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mget_variable_ranges\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mrange_table\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-507fba3ebe57>\u001b[0m in \u001b[0;36mget_variable_ranges\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mranges\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfamily_household_income_range\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mrange_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mranges2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sum_in_area_ranges\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[1;31m# range_table = range_table.reset_index()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ranges2' is not defined"
     ]
    }
   ],
   "source": [
    "#MAKE A FUNCTION\n",
    "def get_variable_ranges():\n",
    "\n",
    "    global ranges, range_table\n",
    "    ranges=[]\n",
    "    for item, i in enumerate(family_household_income_transposed.columns[1:]):\n",
    "        family_household_income_range = np.arange(family_household_income_transposed.min()[item-1]+1, \\\n",
    "                               family_household_income_transposed.max()[item]+1).astype(int)\n",
    "        if family_household_income_transposed.min()[item-1] == family_household_income_transposed.max()[item]:\n",
    "            family_household_income_range = np.arange(family_household_income_transposed.min()[item-2]+1, \\\n",
    "                               family_household_income_transposed.max()[item]).astype(int)\n",
    "       \n",
    "        elif family_household_income_transposed.min()[item-2] == family_household_income_transposed.max()[item]:\n",
    "            family_household_income_range = np.arange(family_household_income_transposed.min()[item-3]+1, \\\n",
    "                               family_household_income_transposed.max()[item]).astype(int)\n",
    "#         elif family_household_income_transposed.min()[item-3] == family_household_income_transposed.max()[item]:\n",
    "#             family_household_income_range = np.arange(family_household_income_transposed.min()[item-4]+1, \\\n",
    "#                                family_household_income_transposed.max()[item]+1).astype(int)        \n",
    "#         elif family_household_income_transposed.min()[item-4] == family_household_income_transposed.max()[item]:\n",
    "#             family_household_income_range = np.arange(family_household_income_transposed.min()[item-5]+1, \\\n",
    "#                                family_household_income_transposed.max()[item]+1).astype(int)   \n",
    "        ranges.append([family_household_income_range])\n",
    "\n",
    "    range_table = pd.DataFrame(data=ranges2, index=None, columns=[\"sum_in_area_ranges\"])\n",
    "    # range_table = range_table.reset_index()\n",
    "\n",
    "    # family_household_income = family_household_income.reset_index()\n",
    "    # family_household_income_with_ranges = pd.merge(range_table, family_household_income, left_index=True, right_index=True, on=None)\n",
    "    # family_household_income_with_ranges\n",
    "\n",
    "get_variable_ranges()\n",
    "\n",
    "range_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def range_per_variable_calculation():\n",
    "    global range_table, ranges, language_range, education_range, household_income_range\n",
    "    ranges=[]\n",
    "    \n",
    "    for item, i in enumerate(language_transposed.columns):\n",
    "        language_range = np.arange(language_transposed.min()[item-1]+1, \\\n",
    "                               language_transposed.max()[item]+1).astype(int)\n",
    "        ranges.append([language_range])\n",
    "        \n",
    "        \n",
    "    for item, i in enumerate(education_transposed.columns):\n",
    "        education_range = np.arange(education_transposed.min()[item-1]+1, \\\n",
    "                               education_transposed.max()[item]+1).astype(int)\n",
    "        ranges.append([education_range])\n",
    "        \n",
    "    for item, i in enumerate(household_income_transposed.columns):\n",
    "        household_income_range = np.arange(household_income_transposed.min()[item-1]+1, \\\n",
    "                               household_income_transposed.max()[item]+1).astype(int)\n",
    "        ranges.append([household_income_range])\n",
    "        \n",
    "#     for item, i in enumerate(school_enrollment_transposed.columns):\n",
    "#         each_range = np.arange(school_enrollment_transposed.min()[item-1]+1, \\\n",
    "#                                school_enrollment_transposed.max()[item]+1).astype(int)\n",
    "#         ranges.append([each_range])\n",
    "\n",
    "    range_table = pd.DataFrame(data=ranges, index=None, columns=[\"sum_in_area_ranges\"])\n",
    "\n",
    "    global percentile_table, range_table_cumulative\n",
    "    \n",
    "    #do for each\n",
    "    percentile_table = percentile_table.reset_index()\n",
    "#     percentile_table = percentile_table.reset_index()\n",
    "#     percentile_table = percentile_table.reset_index()\n",
    "#     percentile_table = percentile_table.reset_index()\n",
    "    range_table = range_table.reset_index()\n",
    "\n",
    "    range_table_cumulative = pd.merge(range_table, percentile_table, left_index=True, right_index=True, on=None)\n",
    "    range_table_cumulative[\"sum_in_area_ranges\"] = range_table_cumulative[\"sum_in_area_ranges\"].astype(str)\n",
    "    range_table_cumulative\n",
    "\n",
    "range_per_variable_calculation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_table_cumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "household_income = df[(df[\"variable_group\"].str.contains('Income'))]\n",
    "household_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "household_income_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_base_text():\n",
    "    for item,i in enumerate(range_table_cumulative.index):\n",
    "        global descriptors, result, result_variable, result_text\n",
    "        descriptors=[]\n",
    "        \n",
    "        if range_table_cumulative[\"sum_ranges\"].str.contains(sum_for_percentile_language).any():\n",
    "            result = range_table_cumulative[range_table_cumulative['sum_ranges'].str.contains(sum_for_percentile_language)]\n",
    "            \n",
    "        elif range_table_cumulative[\"sum_ranges\"].str.contains(sum_for_percentile_education).any():\n",
    "            result = range_table_cumulative[range_table_cumulative['sum_ranges'].str.contains(sum_for_percentile_education)]\n",
    "#     else:\n",
    "#         print(\"Error!\")\n",
    "        result_variable = result[\"variables\"].values[0]\n",
    "\n",
    "        #So returning the data dictionary for this \n",
    "        dict_result = data_dict[data_dict[\"variables\"].str.contains(result_variable)]\n",
    "        result_text = dict_result[\"variable_name\"].values[0]\n",
    "\n",
    "        #then append to empty dataframe that will have the data for text generation\n",
    "        descriptors.append([result_text])\n",
    "            \n",
    "generate_base_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "household_income_range_string = \",\".join(household_income_range.astype(str))\n",
    "# test = range_table.loc[range_table[\"sum_in_area_ranges\"].str.contains(household_income_range_string)]\n",
    "range_table[\"sum_in_area_ranges\"].astype(str).str.contains(household_income_range_string)\n",
    "# type(household_income_range_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptors ... so need to fix this. \n",
    "# need to actually make this loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generation_button = Button(description=\"Generate Text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_text():\n",
    "    percentile_string = \"This description represents the top \"+ str(selected_percentile.value) + \"% of this area's residents.\"\n",
    "    print(percentile_string)\n",
    "    \n",
    "    if (selected_gender.value == \"Male\"):\n",
    "        gender_text = \"she\"\n",
    "    elif (selected_gender.value == \"Female\"):\n",
    "        gender_text = \"he\"\n",
    "    elif (selected_gender.value == \"Both\"):\n",
    "        gender_text = \"they\"\n",
    "        \n",
    "    if (selected_age.value == \"5 to 17 Years\") & (selected_gender.value == \"Total Population\"):\n",
    "        subject_description = \"As a young woman, you \"\n",
    "    else:\n",
    "        subject_description = \"As a young woman, you \"\n",
    "    \n",
    "    if (result_text == \"Speak a Language other than English at Home\"):\n",
    "        language_text = \"In addition to english, \" + gender_text + \" speaks \" + + \" at home.\"\n",
    "#     This young woman is well-educated and has at least a bachelor’s degree. In addition to English, she speaks Spanish at home. She lives with her family, and her household is quite wealthy. She drives to work alone on her short commute. \n",
    "\n",
    "    global resident_string\n",
    "    resident_string = language_text + percentile_string\n",
    "    \n",
    "    with output:\n",
    "        display(resident_string)\n",
    "    \n",
    "replace_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resident_string = \"help\"\n",
    "\n",
    "#TEXT GENERATION\n",
    "def text_generation(b):\n",
    "    output.clear_output()\n",
    "    data_output.clear_output()\n",
    "    \n",
    "    user_selection()\n",
    "    descriptor_generation()\n",
    "    range_per_variable_calculation()\n",
    "    generate_base_text()\n",
    "    \n",
    "    replace_text()    \n",
    "    \n",
    "text_generation_button.on_click(text_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def display_dashboard():\n",
    "    user_selection()\n",
    "    \n",
    "    item_layout = widgets.Layout(margin='0 0 10px 0')\n",
    "    \n",
    "    with output:\n",
    "        display(resident_string)\n",
    "    with data_output:\n",
    "        display(range_table)\n",
    "        \n",
    "    input_widgets = widgets.VBox(\n",
    "        [selected_age, selected_gender, selected_percentile, text_generation_button],\n",
    "        layout=item_layout)\n",
    "    \n",
    "    tab = widgets.Tab([output, data_output],\n",
    "        layout=item_layout)\n",
    "    tab.set_title(0, 'Narrative')\n",
    "    tab.set_title(1, 'Dataset Exploration')\n",
    "    \n",
    "    dashboard = widgets.VBox([input_widgets, tab])\n",
    "    display(dashboard)\n",
    "\n",
    "display_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# widget_control = WidgetControl(widget=text_generation_button, position='topright')\n",
    "# m.add_control(widget_control)\n",
    "\n",
    "# m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
