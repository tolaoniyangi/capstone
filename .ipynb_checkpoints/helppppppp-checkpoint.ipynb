{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point, Polygon\n",
    "import matplotlib.pyplot as plt\n",
    "from fiona.crs import from_epsg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib, json, requests \n",
    "import geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyleaflet import Map, GeoData, GeoJSON, basemaps, basemap_to_tiles, Icon, Circle, Marker, LayerGroup, WidgetControl\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Button \n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need this to stop numpy from returning truncated arrays \n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting basic map\n",
    "center = (40.7210907,-73.9877836)\n",
    "basemap = basemap_to_tiles(basemaps.CartoDB.Positron)\n",
    "\n",
    "m = Map(layers=(basemap, ), center=center, zoom=15, min_zoom = 7, max_zoom = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_location():       \n",
    "    global gdf, lat, lon\n",
    "    \n",
    "    lat = str(markerlocation[0])\n",
    "    lon = str(markerlocation[1])\n",
    "    \n",
    "    df2 = pd.DataFrame(markerlocation)\n",
    "    df=df2.transpose()\n",
    "    df.columns=['Latitude','Longitude']\n",
    "\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.Longitude, df.Latitude), crs='epsg:4326')\n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "draggable=False\n",
    "marker_opacity=1\n",
    "icon = Icon(icon_url='icon.png', icon_size=[15, 15])\n",
    "\n",
    "marker = Marker(location=center, draggable=draggable, icon=icon, opacity=marker_opacity)\n",
    "\n",
    "markerlocation = marker.location \n",
    "\n",
    "layer_group = LayerGroup(layers=(marker, ))\n",
    "m.add_layer(layer_group)\n",
    "   \n",
    "def update_marker(**kwargs):\n",
    "    \n",
    "    if kwargs.get('type') == 'click':\n",
    "        layer_group.clear_layers();\n",
    "        \n",
    "        marker = Marker(location=kwargs.get('coordinates'), draggable=draggable, icon=icon, opacity=marker_opacity, options=['rise_on_hover'])  \n",
    "        \n",
    "        global markerlocation\n",
    "        markerlocation = marker.location \n",
    "        \n",
    "        layer_group.add_layer(marker)\n",
    "    \n",
    "        draw_update_buffer(**kwargs)\n",
    "    \n",
    "m.on_interaction(update_marker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_update_buffer(**kwargs):     \n",
    "    m.on_interaction(update_marker)\n",
    "    extract_location()\n",
    "    \n",
    "    global half_mi\n",
    "    half_mi=gdf.copy()\n",
    "    half_mi['geometry'] = half_mi.geometry.buffer(.004,  cap_style=1, join_style=1)\n",
    "\n",
    "    map_extent = gdf.copy()\n",
    "    map_extent['geometry'] = map_extent.buffer(1,  cap_style=1, join_style=1)\n",
    "\n",
    "    diff = gpd.overlay(map_extent, half_mi, how='difference')\n",
    "    \n",
    "    half_mi_difference = GeoData(geo_dataframe = diff,\n",
    "                       style={'color': \"black\", \\\n",
    "                              'fillColor': \"#000000\", \\\n",
    "                              'fillOpacity': .2, \\\n",
    "                              'opacity': 1, \\\n",
    "                              'weight': 2},\n",
    "                       name = \"Test\", crs='epsg:4326')\n",
    "\n",
    "    layer_group.add_layer(half_mi_difference) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received 12 entries, 12 total\n",
      "Received 1 entries, 13 total\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>GEOID</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>TRACT</th>\n",
       "      <th>NAME</th>\n",
       "      <th>OBJECTID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((-73.98986 40.72053, -73.98962 40.720...</td>\n",
       "      <td>36061003001</td>\n",
       "      <td>36</td>\n",
       "      <td>061</td>\n",
       "      <td>003001</td>\n",
       "      <td>Census Tract 30.01</td>\n",
       "      <td>10843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((-73.99326 40.72235, -73.99352 40.721...</td>\n",
       "      <td>36061003601</td>\n",
       "      <td>36</td>\n",
       "      <td>061</td>\n",
       "      <td>003601</td>\n",
       "      <td>Census Tract 36.01</td>\n",
       "      <td>10846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON ((-73.99155 40.72709, -73.99179 40.726...</td>\n",
       "      <td>36061003800</td>\n",
       "      <td>36</td>\n",
       "      <td>061</td>\n",
       "      <td>003800</td>\n",
       "      <td>Census Tract 38</td>\n",
       "      <td>10847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON ((-73.98788 40.71741, -73.98837 40.716...</td>\n",
       "      <td>36061001402</td>\n",
       "      <td>36</td>\n",
       "      <td>061</td>\n",
       "      <td>001402</td>\n",
       "      <td>Census Tract 14.02</td>\n",
       "      <td>26519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>POLYGON ((-73.98845 40.72328, -73.98864 40.722...</td>\n",
       "      <td>36061003002</td>\n",
       "      <td>36</td>\n",
       "      <td>061</td>\n",
       "      <td>003002</td>\n",
       "      <td>Census Tract 30.02</td>\n",
       "      <td>40986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>POLYGON ((-73.98454 40.71639, -73.98501 40.715...</td>\n",
       "      <td>36061001200</td>\n",
       "      <td>36</td>\n",
       "      <td>061</td>\n",
       "      <td>001200</td>\n",
       "      <td>Census Tract 12</td>\n",
       "      <td>45321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>POLYGON ((-73.99233 40.72491, -73.99260 40.724...</td>\n",
       "      <td>36061003602</td>\n",
       "      <td>36</td>\n",
       "      <td>061</td>\n",
       "      <td>003602</td>\n",
       "      <td>Census Tract 36.02</td>\n",
       "      <td>52962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>POLYGON ((-73.98705 40.72520, -73.98750 40.724...</td>\n",
       "      <td>36061003200</td>\n",
       "      <td>36</td>\n",
       "      <td>061</td>\n",
       "      <td>003200</td>\n",
       "      <td>Census Tract 32</td>\n",
       "      <td>56775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>POLYGON ((-73.99750 40.71407, -73.99744 40.714...</td>\n",
       "      <td>36061001600</td>\n",
       "      <td>36</td>\n",
       "      <td>061</td>\n",
       "      <td>001600</td>\n",
       "      <td>Census Tract 16</td>\n",
       "      <td>71680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>POLYGON ((-73.99442 40.71939, -73.99481 40.718...</td>\n",
       "      <td>36061001800</td>\n",
       "      <td>36</td>\n",
       "      <td>061</td>\n",
       "      <td>001800</td>\n",
       "      <td>Census Tract 18</td>\n",
       "      <td>71681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>POLYGON ((-73.98448 40.72024, -73.98507 40.719...</td>\n",
       "      <td>36061002201</td>\n",
       "      <td>36</td>\n",
       "      <td>061</td>\n",
       "      <td>002201</td>\n",
       "      <td>Census Tract 22.01</td>\n",
       "      <td>71962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>POLYGON ((-73.98344 40.72202, -73.98382 40.721...</td>\n",
       "      <td>36061002202</td>\n",
       "      <td>36</td>\n",
       "      <td>061</td>\n",
       "      <td>002202</td>\n",
       "      <td>Census Tract 22.02</td>\n",
       "      <td>71963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>POLYGON ((-73.98344 40.72202, -73.98382 40.721...</td>\n",
       "      <td>36061002202</td>\n",
       "      <td>36</td>\n",
       "      <td>061</td>\n",
       "      <td>002202</td>\n",
       "      <td>Census Tract 22.02</td>\n",
       "      <td>71963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             geometry        GEOID STATE  \\\n",
       "0   POLYGON ((-73.98986 40.72053, -73.98962 40.720...  36061003001    36   \n",
       "1   POLYGON ((-73.99326 40.72235, -73.99352 40.721...  36061003601    36   \n",
       "2   POLYGON ((-73.99155 40.72709, -73.99179 40.726...  36061003800    36   \n",
       "3   POLYGON ((-73.98788 40.71741, -73.98837 40.716...  36061001402    36   \n",
       "4   POLYGON ((-73.98845 40.72328, -73.98864 40.722...  36061003002    36   \n",
       "5   POLYGON ((-73.98454 40.71639, -73.98501 40.715...  36061001200    36   \n",
       "6   POLYGON ((-73.99233 40.72491, -73.99260 40.724...  36061003602    36   \n",
       "7   POLYGON ((-73.98705 40.72520, -73.98750 40.724...  36061003200    36   \n",
       "8   POLYGON ((-73.99750 40.71407, -73.99744 40.714...  36061001600    36   \n",
       "9   POLYGON ((-73.99442 40.71939, -73.99481 40.718...  36061001800    36   \n",
       "10  POLYGON ((-73.98448 40.72024, -73.98507 40.719...  36061002201    36   \n",
       "11  POLYGON ((-73.98344 40.72202, -73.98382 40.721...  36061002202    36   \n",
       "12  POLYGON ((-73.98344 40.72202, -73.98382 40.721...  36061002202    36   \n",
       "\n",
       "   COUNTY   TRACT                NAME  OBJECTID  \n",
       "0     061  003001  Census Tract 30.01     10843  \n",
       "1     061  003601  Census Tract 36.01     10846  \n",
       "2     061  003800     Census Tract 38     10847  \n",
       "3     061  001402  Census Tract 14.02     26519  \n",
       "4     061  003002  Census Tract 30.02     40986  \n",
       "5     061  001200     Census Tract 12     45321  \n",
       "6     061  003602  Census Tract 36.02     52962  \n",
       "7     061  003200     Census Tract 32     56775  \n",
       "8     061  001600     Census Tract 16     71680  \n",
       "9     061  001800     Census Tract 18     71681  \n",
       "10    061  002201  Census Tract 22.01     71962  \n",
       "11    061  002202  Census Tract 22.02     71963  \n",
       "12    061  002202  Census Tract 22.02     71963  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def import_censustracts():\n",
    "    draw_update_buffer()\n",
    "    \n",
    "    bounding_box = half_mi.envelope\n",
    "    df = gpd.GeoDataFrame(gpd.GeoSeries(bounding_box), columns=['geometry'])\n",
    "    minx, miny, maxx, maxy = df.geometry.total_bounds\n",
    "    bounds = minx, miny, maxx, maxy\n",
    "\n",
    "    # census tracts link\n",
    "    endpoint = 'https://tigerweb.geo.census.gov/arcgis/rest/services/TIGERweb/Tracts_Blocks/MapServer/4/query'\n",
    "    s = requests.session()\n",
    "    s.params = {\n",
    "        'geometry': str(bounds),\n",
    "        'geometryType': 'esriGeometryEnvelope',\n",
    "        'inSR': 4326,\n",
    "        'spatialRel': 'esriSpatialRelIntersects',\n",
    "        'outFields': 'GEOID,STATE,COUNTY,TRACT,NAME,STGEOMETRY,OBJECTID',\n",
    "        'returnGeometry': True,\n",
    "        'f': 'geojson',        \n",
    "    }\n",
    "    start = 0\n",
    "    done = False\n",
    "    features = []\n",
    "    crs = None\n",
    "    while not done:\n",
    "        r = s.get(endpoint, params={\n",
    "            'resultOffset': start,\n",
    "            'resultRecordCount': 32,\n",
    "        })\n",
    "        censusgeo = geojson.loads(r.text)\n",
    "        newfeats = censusgeo.__geo_interface__['features']\n",
    "        if newfeats:\n",
    "            features.extend(newfeats)\n",
    "            crs=censusgeo.__geo_interface__['crs']\n",
    "            start += len(newfeats)\n",
    "            print(\"Received\", len(newfeats), \"entries,\", start, \"total\")\n",
    "        else:\n",
    "            done = True\n",
    "    \n",
    "    global tracts\n",
    "    tracts = gpd.GeoDataFrame.from_features(features, crs=crs)\n",
    "    return tracts\n",
    "\n",
    "import_censustracts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_acs():  \n",
    "    state = tracts[\"STATE\"].unique().tolist()\n",
    "    state = ', '.join(map(str, state)).replace(\" \", \"\")\n",
    "\n",
    "    tract = tracts[\"TRACT\"].unique().tolist()\n",
    "    tract = ', '.join(map(str, tract)).replace(\" \", \"\") \n",
    "\n",
    "    county = tracts[\"COUNTY\"].unique().tolist()\n",
    "    county = ', '.join(map(str, county)).replace(\" \", \"\") \n",
    "\n",
    "    api_key = '9330dc4bf086a84f19fb412bb15f232507301de6'\n",
    "    acs_url = f'https://api.census.gov/data/2018/acs/acs5/subject/'\n",
    "    \n",
    "    global acs_variables\n",
    "    acs_variables_initial = 'S1901_C04_001E,S1901_C01_001E,S1603_C02_002E,S1603_C02_003E,S1603_C02_004E,S1601_C01_005E,S1601_C01_006E,S1601_C01_007E,S1601_C01_009E,S1601_C01_010E,S1601_C01_011E,S1601_C01_013E,S1601_C01_014E,S1601_C01_015E,S1601_C01_017E,S1601_C01_018E,S1601_C01_019E,S1901_C01_002E,S1901_C01_003E,S1901_C01_004E,S1901_C01_005E,S1901_C01_006E,S1901_C01_007E,S1901_C01_008E,S1901_C01_009E,S1901_C01_010E,S1901_C01_011E,S1901_C04_002E,S1901_C04_003E,S1901_C04_004E,S1901_C04_005E,S1901_C04_006E,S1901_C04_007E,S1901_C04_008E,S1901_C04_009E,S1901_C04_010E,S1901_C04_011E'\n",
    "    acs_variables_additional = 'S1501_C01_002E,S1501_C01_004E,S1501_C01_003E,S1501_C01_005E,S1501_C01_017E,S1501_C01_018E,S1501_C01_020E,S1501_C01_021E,S1501_C01_023E,S1501_C01_024E,S1501_C01_025E,S1501_C01_026E,S1501_C03_002E,S1501_C03_003E,S1501_C03_004E,S1501_C03_005E,S1501_C03_017E,S1501_C03_018E,S1501_C03_020E,S1501_C03_021E,S1501_C03_023E,S1501_C03_024E,S1501_C03_026E,S1501_C03_027E,S1501_C05_002E,S1501_C05_003E,S1501_C05_004E,S1501_C05_005E,S1501_C05_017E,S1501_C05_018E,S1501_C05_020E,S1501_C05_021E,S1501_C05_023E,S1501_C05_024E,S1501_C05_026E,S1501_C05_027E,S1401_C01_030E,S1401_C01_032E,S1401_C01_034E'\n",
    "    acs_variables = acs_variables_initial + \",\" + acs_variables_additional\n",
    "    \n",
    "    get_acs_initial = f'{acs_url}?&get={acs_variables_initial}&for=tract:{tract}&in=state:{state}%20county:{county}&key={api_key}'\n",
    "    get_acs_additional = f'{acs_url}?&get={acs_variables_additional}&for=tract:{tract}&in=state:{state}%20county:{county}&key={api_key}'\n",
    "\n",
    "    data_acs_initial=requests.get(get_acs_initial).json()\n",
    "    data_acs_additional=requests.get(get_acs_additional).json()\n",
    "    \n",
    "    global acs\n",
    "    acs_initial=pd.DataFrame(data_acs_initial[1:], columns=data_acs_initial[0])\n",
    "    acs_additional=pd.DataFrame(data_acs_additional[1:], columns=data_acs_additional[0])\n",
    "\n",
    "    acs=pd.merge(acs_initial, acs_additional, on='tract', how='left')\n",
    "\n",
    "download_acs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#any null rows?\n",
    "test = acs.columns[acs.isnull().any()]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acs = acs.drop(['S0901_C01_033E', 'S0901_C01_034E', 'S0902_C01_003E', 'S0902_C01_004E','S0902_C01_005E'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_combine_census_and_geographic_data():\n",
    "    global acs_site_sum\n",
    "    tracts[\"area\"]=tracts.area\n",
    "    acs_tracts = pd.merge(tracts, acs, left_on='TRACT', right_on='tract', how='left')\n",
    "    tracts_clipped = gpd.overlay(half_mi, acs_tracts, how='intersection')\n",
    "    tracts_clipped[\"area_clipped\"]=tracts_clipped.area \n",
    "    \n",
    "    acs_site=tracts_clipped.copy()\n",
    "    \n",
    "    cols = acs_variables.split(\",\")\n",
    "#      woah not actually done the proportional multiplication here\n",
    "    acs_site[cols] = acs_site[cols].apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "\n",
    "    acs_site_sum = pd.DataFrame(acs_site[cols].sum().astype(int))\n",
    "\n",
    "    acs_site_sum.reset_index(inplace=True)\n",
    "    acs_site_sum.columns = ['variables', 'sum_in_area']\n",
    "    \n",
    "clean_combine_census_and_geographic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age_group</th>\n",
       "      <th>variable_group</th>\n",
       "      <th>variables</th>\n",
       "      <th>variable_name</th>\n",
       "      <th>variable_description</th>\n",
       "      <th>ages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Both</td>\n",
       "      <td>5 to 17 years</td>\n",
       "      <td>Language Spoken At Home</td>\n",
       "      <td>S1603_C02_002E</td>\n",
       "      <td>Speak Only English at Home</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Both</td>\n",
       "      <td>18 to 64 years</td>\n",
       "      <td>Language Spoken At Home</td>\n",
       "      <td>S1603_C02_003E</td>\n",
       "      <td>Speak Only English at Home</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18, 19, 20, 21, 22, 23, 24, 25,26, 27, 28, 29,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Both</td>\n",
       "      <td>65 years and over</td>\n",
       "      <td>Language Spoken At Home</td>\n",
       "      <td>S1603_C02_004E</td>\n",
       "      <td>Speak Only English at Home</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Both</td>\n",
       "      <td>5 to 17 years</td>\n",
       "      <td>Language Spoken At Home</td>\n",
       "      <td>S1603_C04_002E</td>\n",
       "      <td>Speak a Language other than English at Home</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Both</td>\n",
       "      <td>18 to 64 years</td>\n",
       "      <td>Language Spoken At Home</td>\n",
       "      <td>S1603_C04_003E</td>\n",
       "      <td>Speak a Language other than English at Home</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18, 19, 20, 21, 22, 23, 24, 25,26, 27, 28, 29,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>Female</td>\n",
       "      <td>65 years and over</td>\n",
       "      <td>Educational Attainment</td>\n",
       "      <td>S1501_C05_026E</td>\n",
       "      <td>High school graduate or higher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>Female</td>\n",
       "      <td>65 years and over</td>\n",
       "      <td>Educational Attainment</td>\n",
       "      <td>S1501_C05_027E</td>\n",
       "      <td>Bachelor's degree or higher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>Both</td>\n",
       "      <td>18 to 24 years</td>\n",
       "      <td>School Enrollment</td>\n",
       "      <td>S1401_C01_030E</td>\n",
       "      <td>Enrolled in college or graduate school</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18, 19, 20, 21, 22, 23, 24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>Male</td>\n",
       "      <td>18 to 24 years</td>\n",
       "      <td>School Enrollment</td>\n",
       "      <td>S1401_C01_032E</td>\n",
       "      <td>Enrolled in college or graduate school</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18, 19, 20, 21, 22, 23, 24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>Female</td>\n",
       "      <td>18 to 24 years</td>\n",
       "      <td>School Enrollment</td>\n",
       "      <td>S1401_C01_034E</td>\n",
       "      <td>Enrolled in college or graduate school</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18, 19, 20, 21, 22, 23, 24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sex           age_group           variable_group       variables  \\\n",
       "0     Both       5 to 17 years  Language Spoken At Home  S1603_C02_002E   \n",
       "1     Both      18 to 64 years  Language Spoken At Home  S1603_C02_003E   \n",
       "2     Both  65 years and over   Language Spoken At Home  S1603_C02_004E   \n",
       "3     Both       5 to 17 years  Language Spoken At Home  S1603_C04_002E   \n",
       "4     Both      18 to 64 years  Language Spoken At Home  S1603_C04_003E   \n",
       "..     ...                 ...                      ...             ...   \n",
       "72  Female   65 years and over   Educational Attainment  S1501_C05_026E   \n",
       "73  Female   65 years and over   Educational Attainment  S1501_C05_027E   \n",
       "74    Both      18 to 24 years        School Enrollment  S1401_C01_030E   \n",
       "75    Male      18 to 24 years        School Enrollment  S1401_C01_032E   \n",
       "76  Female      18 to 24 years        School Enrollment  S1401_C01_034E   \n",
       "\n",
       "                                  variable_name variable_description  \\\n",
       "0                    Speak Only English at Home                  NaN   \n",
       "1                    Speak Only English at Home                  NaN   \n",
       "2                    Speak Only English at Home                  NaN   \n",
       "3   Speak a Language other than English at Home                  NaN   \n",
       "4   Speak a Language other than English at Home                  NaN   \n",
       "..                                          ...                  ...   \n",
       "72               High school graduate or higher                  NaN   \n",
       "73                  Bachelor's degree or higher                  NaN   \n",
       "74       Enrolled in college or graduate school                  NaN   \n",
       "75       Enrolled in college or graduate school                  NaN   \n",
       "76       Enrolled in college or graduate school                  NaN   \n",
       "\n",
       "                                                 ages  \n",
       "0       5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17  \n",
       "1   18, 19, 20, 21, 22, 23, 24, 25,26, 27, 28, 29,...  \n",
       "2   64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75...  \n",
       "3       5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17  \n",
       "4   18, 19, 20, 21, 22, 23, 24, 25,26, 27, 28, 29,...  \n",
       "..                                                ...  \n",
       "72  65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76...  \n",
       "73  65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76...  \n",
       "74                         18, 19, 20, 21, 22, 23, 24  \n",
       "75                         18, 19, 20, 21, 22, 23, 24  \n",
       "76                         18, 19, 20, 21, 22, 23, 24  \n",
       "\n",
       "[77 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = pd.read_csv(\"data-dictionary.csv\")\n",
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use this if i decide to add in the option to select all\n",
    "ALL = 'ALL'\n",
    "def user_options_sorted_values_plus_ALL(array):\n",
    "    unique = array.unique().tolist()\n",
    "    unique.sort()\n",
    "    unique.insert(0, ALL)\n",
    "    return unique\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_options_sorted_values(array):\n",
    "    unique = array.unique().tolist()\n",
    "    unique.sort()\n",
    "    return unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = widgets.Output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_output = widgets.Output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def user_selection():\n",
    "    \n",
    "    output.clear_output()\n",
    "    data_output.clear_output() \n",
    "    \n",
    "    global selected_age, selected_gender, selected_percentile, text_generation_button, selection_filter, variable_inputs\n",
    "#     selected_age = widgets.Dropdown(options = user_options_sorted_values(data_dict.age_group),\\\n",
    "#                                     value = \"5 to 17 Years\")\n",
    "    selected_age = widgets.BoundedIntText(min=5, max=99, value=25, step=1, description='Age:')\n",
    "    selected_gender = widgets.ToggleButtons(options = user_options_sorted_values(data_dict.sex),\\\n",
    "                                            value = \"Male\",\\\n",
    "                                            description='Sex:', \\\n",
    "                                            disabled=False, button_style='', )\n",
    "    selected_percentile = widgets.IntSlider(min=0, max=100, step=10, value=50, description='Percentile:',)\n",
    "    text_generation_button = Button(description=\"Generate Text\")\n",
    "    \n",
    "#     display(selected_age, selected_gender, selected_percentile, output)\n",
    "    \n",
    "    selected_age_str= str(selected_age.value)\n",
    "\n",
    "    selection_filter = data_dict[(data_dict.ages.str.contains(selected_age_str)) & \n",
    "                              ((data_dict.sex == selected_gender.value) |\n",
    "                              (data_dict.sex == \"Both\"))]   \n",
    "    \n",
    "    with data_output:\n",
    "            display(selection_filter)\n",
    "    \n",
    "    def selection_filtering(age_group, sex):\n",
    "        output.clear_output()\n",
    "        data_output.clear_output()\n",
    "\n",
    "        selected_age_str= str(selected_age.value)\n",
    "        \n",
    "        selection_filter = data_dict[(data_dict.ages.str.contains(selected_age_str)) & \n",
    "                                  ((data_dict.sex == selected_gender.value) |\n",
    "                                    (data_dict.sex == \"Both\"))]   \n",
    "        with data_output:\n",
    "            display(selection_filter)\n",
    "\n",
    "    def selected_age_eventhandler(change):\n",
    "        selection_filtering(change.new, selected_age.value)\n",
    "    def selected_gender_eventhandler(change):\n",
    "        selection_filtering(selected_gender.value, change.new)\n",
    "    def selected_percentile_eventhandler(change):\n",
    "        selection_filtering(selected_percentile.value, change.new)\n",
    "\n",
    "    selected_age.observe(selected_age_eventhandler, names='value')\n",
    "    selected_gender.observe(selected_gender_eventhandler, names='value')\n",
    "    selected_percentile.observe(selected_percentile_eventhandler, names='value')\n",
    "\n",
    "    list_of_variable_inputs = selection_filter[\"variables\"].values[0:]\n",
    "    variable_inputs = ', '.join(list_of_variable_inputs).replace(\" \", \"\")\n",
    "    variable_inputs = variable_inputs.split(',')\n",
    "    \n",
    "user_selection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def descriptor_generation():\n",
    "# # eventually would need to split these up into the diff bins for different types of variable groups \n",
    "#     global df\n",
    "#     df = pd.merge(acs_site_sum.loc[acs_site_sum['variables'].isin(variable_inputs)], \\\n",
    "#                    selection_filter, how=\"right\", on=\"variables\")    \n",
    "\n",
    "# # calculate percentile_input_per_variable\n",
    "#     global sum_for_percentile, percentile_input, percentile_table, percentile_table_transposed\n",
    "\n",
    "# #adding in 0 value to dataframe...to have complete table for the percentiles \n",
    "#     percentile_table = df.append({'sum_in_area' : 0, 'variables':'Baseline_Value',\\\n",
    "#                                   'variable_group':'Baseline_Group'}, ignore_index=True)\n",
    "#     percentile_table.sort_values(\"sum_in_area\", axis = 0, ascending = True, inplace = True)\n",
    "\n",
    "# #10th percentile = 0.1\n",
    "#     percentile_input = selected_percentile.value / 100\n",
    "\n",
    "# # split these up into the diff bins for different types of variable groups \n",
    "#     global language, education, household_income, school_enrollment\n",
    "\n",
    "#     for item,i in enumerate(df):       \n",
    "#         language = percentile_table[(percentile_table[\"variable_group\"].str.contains('Language|Baseline_Group'))]\n",
    "#         education = percentile_table[(percentile_table[\"variable_group\"].str.contains('Educational Attainment|Baseline_Group'))]\n",
    "#         school_enrollment = percentile_table[(percentile_table[\"variable_group\"].str.contains('School|Baseline_Group'))]\n",
    "#         household_income = percentile_table[(percentile_table[\"variable_group\"].str.contains('Income|Baseline_Group'))]\n",
    "# #       travel_time_to_work = percentile_table[(percentile_table[\"variable_group\"].str.contains('Travel Time'))]\n",
    "#         # means_of_transportation = percentile_table[(percentile_table[\"variable_group\"].str.contains('Means of Transportation'))]\n",
    "\n",
    "# # do this instead for the language tables etc \n",
    "#     global sum_for_percentile_language,sum_for_percentile_education,sum_for_percentile_school_enrollment,sum_for_percentile_household_income\n",
    "#     sum_for_percentile_language = language.sum_in_area.quantile(percentile_input).astype(int).astype(str)\n",
    "#     sum_for_percentile_education = education.sum_in_area.quantile(percentile_input).astype(int).astype(str)\n",
    "#     sum_for_percentile_school_enrollment = school_enrollment.sum_in_area.quantile(percentile_input).astype(int).astype(str)    \n",
    "#     sum_for_percentile_household_income = household_income.sum_in_area.quantile(percentile_input).astype(int).astype(str)\n",
    "    \n",
    "# #generating new transposed table with only the two fields needed : variables and sum in area.\n",
    "# #using other variables makes transposition weird\n",
    "#     global language_transposed, education_transposed, household_income_transposed, school_enrollment_transposed\n",
    "\n",
    "#     language_transposed = language.filter([\"variables\", \"sum_in_area\"]).T\n",
    "#     language_transposed.columns = language_transposed.iloc[0]\n",
    "#     language_transposed = language_transposed[1:]\n",
    "\n",
    "#     education_transposed = education.filter([\"variables\", \"sum_in_area\"]).T\n",
    "#     education_transposed.columns = education_transposed.iloc[0]\n",
    "#     education_transposed = education_transposed[1:]\n",
    "    \n",
    "#     household_income_transposed = household_income.filter([\"variables\", \"sum_in_area\"]).T\n",
    "#     household_income_transposed.columns = household_income_transposed.iloc[0]\n",
    "#     household_income_transposed = household_income_transposed[1:]    \n",
    "    \n",
    "# #     school_enrollment_transposed = school_enrollment.filter([\"variables\", \"sum_in_area\"]).T\n",
    "# #     school_enrollment_transposed.columns = school_enrollment_transposed.iloc[0]\n",
    "# #     school_enrollment_transposed = school_enrollment_transposed[1:]    \n",
    "    \n",
    "# descriptor_generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptor_generation():\n",
    "# eventually would need to split these up into the diff bins for different types of variable groups \n",
    "# so we have the big dataframe with only the selected ages etc \n",
    "    global df\n",
    "#     df = pd.merge(acs_site_sum.loc[acs_site_sum['variables'].isin(variable_inputs)], \\\n",
    "#                    selection_filter, how=\"right\", on=\"variables\")    \n",
    "    df = pd.merge(acs_site_sum, \\\n",
    "                   selection_filter, how=\"inner\", on=\"variables\")    \n",
    "# calculate percentile_input_per_variable\n",
    "    global sum_for_percentile, percentile_input, percentile_table, percentile_table_transposed\n",
    "\n",
    "#adding in 0 value to dataframe...to have complete table for the percentiles \n",
    "    percentile_table = df.append({'sum_in_area' : 0, 'variables':'Baseline_Value',\\\n",
    "                                  'variable_group':'Baseline_Group'}, ignore_index=True)\n",
    "    percentile_table.sort_values(\"sum_in_area\", axis = 0, ascending = True, inplace = True)\n",
    "\n",
    "#10th percentile = 0.1\n",
    "    percentile_input = selected_percentile.value / 100\n",
    "\n",
    "# split these up into the diff bins for different types of variable groups \n",
    "    global language, education, household_type, family_household_income, nonfamily_household_income, school_enrollment\n",
    "\n",
    "    for item,i in enumerate(df):       \n",
    "        language = percentile_table[(percentile_table[\"variable_group\"].str.contains('Language|Baseline_Group'))]\n",
    "        education = percentile_table[(percentile_table[\"variable_group\"].str.contains('Educational Attainment|Baseline_Group'))]\n",
    "        school_enrollment = percentile_table[(percentile_table[\"variable_group\"].str.contains('School|Baseline_Group'))]\n",
    "        household_type = percentile_table[(percentile_table[\"variable_group\"].str.contains('Household|Baseline_Group'))]\n",
    "        family_household_income = percentile_table[(percentile_table[\"variable_group\"].str.contains('Income|Baseline_Group'))]\n",
    "        nonfamily_household_income = percentile_table[(percentile_table[\"variable_group\"].str.contains('Income|Baseline_Group'))]\n",
    "#       travel_time_to_work = percentile_table[(percentile_table[\"variable_group\"].str.contains('Travel Time'))]\n",
    "        # means_of_transportation = percentile_table[(percentile_table[\"variable_group\"].str.contains('Means of Transportation'))]\n",
    "\n",
    "# do this instead for the language tables etc \n",
    "    global sum_for_percentile_language,sum_for_percentile_education,sum_for_percentile_school_enrollment,sum_for_percentile_household_income\n",
    "    sum_for_percentile_language = language.sum_in_area.quantile(percentile_input).astype(int).astype(str)\n",
    "    sum_for_percentile_education = education.sum_in_area.quantile(percentile_input).astype(int).astype(str)\n",
    "    sum_for_percentile_school_enrollment = school_enrollment.sum_in_area.quantile(percentile_input).astype(int).astype(str)    \n",
    "    sum_for_percentile_household_type= household_type.sum_in_area.quantile(percentile_input).astype(int).astype(str)\n",
    "    sum_for_percentile_family_household_income = family_household_income.sum_in_area.quantile(percentile_input).astype(int).astype(str)\n",
    "    sum_for_percentile_nonfamily_household_income = nonfamily_household_income.sum_in_area.quantile(percentile_input).astype(int).astype(str)\n",
    "    \n",
    "#generating new transposed table with only the two fields needed : variables and sum in area.\n",
    "#using other variables makes transposition weird\n",
    "    global language_transposed, education_transposed, household_type_transposed, family_household_income_transposed, nonfamily_household_income_transposed, school_enrollment_transposed\n",
    "\n",
    "    language_transposed = language.filter([\"variables\", \"sum_in_area\"]).T\n",
    "    language_transposed.columns = language_transposed.iloc[0]\n",
    "    language_transposed = language_transposed[1:]\n",
    "\n",
    "    education_transposed = education.filter([\"variables\", \"sum_in_area\"]).T\n",
    "    education_transposed.columns = education_transposed.iloc[0]\n",
    "    education_transposed = education_transposed[1:]\n",
    "    \n",
    "    household_type_transposed = household_type.filter([\"variables\", \"sum_in_area\"]).T\n",
    "    household_type_transposed.columns = household_type_transposed.iloc[0]\n",
    "    household_type_transposed = household_type_transposed[1:]    \n",
    "    \n",
    "    family_household_income_transposed = family_household_income.filter([\"variables\", \"sum_in_area\"]).T\n",
    "    family_household_income_transposed.columns = family_household_income_transposed.iloc[0]\n",
    "    family_household_income_transposed = family_household_income_transposed[1:]\n",
    "    \n",
    "    nonfamily_household_income_transposed = nonfamily_household_income.filter([\"variables\", \"sum_in_area\"]).T\n",
    "    nonfamily_household_income_transposed.columns = nonfamily_household_income_transposed.iloc[0]\n",
    "    nonfamily_household_income_transposed = nonfamily_household_income_transposed[1:]\n",
    "    \n",
    "#     school_enrollment_transposed = school_enrollment.filter([\"variables\", \"sum_in_area\"]).T\n",
    "#     school_enrollment_transposed.columns = school_enrollment_transposed.iloc[0]\n",
    "#     school_enrollment_transposed = school_enrollment_transposed[1:]    \n",
    "    \n",
    "descriptor_generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_in_area_ranges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[66, 67, 68, 69, 70, 71, 72]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[73]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>[86, 87, 88]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>[89, 90, 91, 92]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>[93, 94, 95, 96]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>[93, 94, 95, 96]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>[97, 98]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>[99, 100, 101]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>[102, 103, 104]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>[105, 106, 107]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>[108, 109, 110, 111, 112, 113]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>[108, 109, 110, 111, 112, 113]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>[114, 115, 116, 117, 118, 119, 120, 121, 122, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>[114, 115, 116, 117, 118, 119, 120, 121, 122, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>[132, 133, 134, 135, 136, 137, 138, 139, 140, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>[171, 172, 173, 174]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>[175, 176, 177, 178, 179, 180, 181, 182, 183, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   sum_in_area_ranges\n",
       "0                                                  []\n",
       "1   [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...\n",
       "2                        [66, 67, 68, 69, 70, 71, 72]\n",
       "3                                                [73]\n",
       "4    [74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85]\n",
       "5                                        [86, 87, 88]\n",
       "6                                    [89, 90, 91, 92]\n",
       "7                                    [93, 94, 95, 96]\n",
       "8                                    [93, 94, 95, 96]\n",
       "9                                                  []\n",
       "10                                           [97, 98]\n",
       "11                                     [99, 100, 101]\n",
       "12                                    [102, 103, 104]\n",
       "13                                    [105, 106, 107]\n",
       "14                     [108, 109, 110, 111, 112, 113]\n",
       "15                     [108, 109, 110, 111, 112, 113]\n",
       "16  [114, 115, 116, 117, 118, 119, 120, 121, 122, ...\n",
       "17  [114, 115, 116, 117, 118, 119, 120, 121, 122, ...\n",
       "18  [132, 133, 134, 135, 136, 137, 138, 139, 140, ...\n",
       "19                               [171, 172, 173, 174]\n",
       "20  [175, 176, 177, 178, 179, 180, 181, 182, 183, ..."
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MAKE A FUNCTION\n",
    "def get_variable_ranges():\n",
    "\n",
    "    global ranges, range_table\n",
    "    ranges=[]\n",
    "    for item, i in enumerate(family_household_income_transposed.columns[1:]):\n",
    "        family_household_income_range = np.arange(family_household_income_transposed.min()[item-1]+1, \\\n",
    "                               family_household_income_transposed.max()[item]+1).astype(int)\n",
    "        if family_household_income_transposed.min()[item-1] == family_household_income_transposed.max()[item]:\n",
    "            family_household_income_range = np.arange(family_household_income_transposed.min()[item-2]+1, \\\n",
    "                               family_household_income_transposed.max()[item]).astype(int)\n",
    "       \n",
    "        elif family_household_income_transposed.min()[item-2] == family_household_income_transposed.max()[item]:\n",
    "            family_household_income_range = np.arange(family_household_income_transposed.min()[item-3]+1, \\\n",
    "                               family_household_income_transposed.max()[item]).astype(int)\n",
    "#         elif family_household_income_transposed.min()[item-3] == family_household_income_transposed.max()[item]:\n",
    "#             family_household_income_range = np.arange(family_household_income_transposed.min()[item-4]+1, \\\n",
    "#                                family_household_income_transposed.max()[item]+1).astype(int)        \n",
    "#         elif family_household_income_transposed.min()[item-4] == family_household_income_transposed.max()[item]:\n",
    "#             family_household_income_range = np.arange(family_household_income_transposed.min()[item-5]+1, \\\n",
    "#                                family_household_income_transposed.max()[item]+1).astype(int)   \n",
    "        ranges.append([family_household_income_range])\n",
    "\n",
    "    range_table = pd.DataFrame(data=ranges2, index=None, columns=[\"sum_in_area_ranges\"])\n",
    "    # range_table = range_table.reset_index()\n",
    "\n",
    "    # family_household_income = family_household_income.reset_index()\n",
    "    # family_household_income_with_ranges = pd.merge(range_table, family_household_income, left_index=True, right_index=True, on=None)\n",
    "    # family_household_income_with_ranges\n",
    "\n",
    "get_variable_ranges()\n",
    "\n",
    "range_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def range_per_variable_calculation():\n",
    "    global range_table, ranges, language_range, education_range, household_income_range\n",
    "    ranges=[]\n",
    "    \n",
    "    for item, i in enumerate(language_transposed.columns):\n",
    "        language_range = np.arange(language_transposed.min()[item-1]+1, \\\n",
    "                               language_transposed.max()[item]+1).astype(int)\n",
    "        ranges.append([language_range])\n",
    "        \n",
    "        \n",
    "    for item, i in enumerate(education_transposed.columns):\n",
    "        education_range = np.arange(education_transposed.min()[item-1]+1, \\\n",
    "                               education_transposed.max()[item]+1).astype(int)\n",
    "        ranges.append([education_range])\n",
    "        \n",
    "    for item, i in enumerate(household_income_transposed.columns):\n",
    "        household_income_range = np.arange(household_income_transposed.min()[item-1]+1, \\\n",
    "                               household_income_transposed.max()[item]+1).astype(int)\n",
    "        ranges.append([household_income_range])\n",
    "        \n",
    "#     for item, i in enumerate(school_enrollment_transposed.columns):\n",
    "#         each_range = np.arange(school_enrollment_transposed.min()[item-1]+1, \\\n",
    "#                                school_enrollment_transposed.max()[item]+1).astype(int)\n",
    "#         ranges.append([each_range])\n",
    "\n",
    "    range_table = pd.DataFrame(data=ranges, index=None, columns=[\"sum_in_area_ranges\"])\n",
    "\n",
    "    global percentile_table, range_table_cumulative\n",
    "    \n",
    "    #do for each\n",
    "    percentile_table = percentile_table.reset_index()\n",
    "#     percentile_table = percentile_table.reset_index()\n",
    "#     percentile_table = percentile_table.reset_index()\n",
    "#     percentile_table = percentile_table.reset_index()\n",
    "    range_table = range_table.reset_index()\n",
    "\n",
    "    range_table_cumulative = pd.merge(range_table, percentile_table, left_index=True, right_index=True, on=None)\n",
    "    range_table_cumulative[\"sum_in_area_ranges\"] = range_table_cumulative[\"sum_in_area_ranges\"].astype(str)\n",
    "    range_table_cumulative\n",
    "\n",
    "range_per_variable_calculation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_x</th>\n",
       "      <th>sum_in_area_ranges</th>\n",
       "      <th>index_y</th>\n",
       "      <th>variables</th>\n",
       "      <th>sum_in_area</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_group</th>\n",
       "      <th>variable_group</th>\n",
       "      <th>variable_name</th>\n",
       "      <th>variable_description</th>\n",
       "      <th>ages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>29</td>\n",
       "      <td>Baseline_Value</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Baseline_Group</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[  1   2   3   4   5   6   7   8   9  10  11  ...</td>\n",
       "      <td>18</td>\n",
       "      <td>S1901_C04_005E</td>\n",
       "      <td>65</td>\n",
       "      <td>Both</td>\n",
       "      <td>all ages</td>\n",
       "      <td>Income In The Past 12 Months (in 2018 Inflatio...</td>\n",
       "      <td>NF4</td>\n",
       "      <td>Nonfamily Household Income $25,000 to $34,999</td>\n",
       "      <td>5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[ 613  614  615  616  617  618  619  620  621 ...</td>\n",
       "      <td>19</td>\n",
       "      <td>S1901_C04_006E</td>\n",
       "      <td>72</td>\n",
       "      <td>Both</td>\n",
       "      <td>all ages</td>\n",
       "      <td>Income In The Past 12 Months (in 2018 Inflatio...</td>\n",
       "      <td>NF5</td>\n",
       "      <td>Nonfamily Household Income $35,000 to $49,999</td>\n",
       "      <td>5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[2694 2695 2696 2697 2698 2699 2700 2701 2702 ...</td>\n",
       "      <td>8</td>\n",
       "      <td>S1901_C01_005E</td>\n",
       "      <td>73</td>\n",
       "      <td>Both</td>\n",
       "      <td>all ages</td>\n",
       "      <td>Income In The Past 12 Months (in 2018 Inflatio...</td>\n",
       "      <td>F4</td>\n",
       "      <td>Family Household Income $25,000 to $34,999</td>\n",
       "      <td>5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[5219 5220 5221 5222 5223 5224 5225 5226 5227 ...</td>\n",
       "      <td>9</td>\n",
       "      <td>S1901_C01_006E</td>\n",
       "      <td>85</td>\n",
       "      <td>Both</td>\n",
       "      <td>all ages</td>\n",
       "      <td>Income In The Past 12 Months (in 2018 Inflatio...</td>\n",
       "      <td>F5</td>\n",
       "      <td>Family Household Income $35,000 to $49,999</td>\n",
       "      <td>5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>[ 5842  5843  5844  5845  5846  5847  5848  58...</td>\n",
       "      <td>17</td>\n",
       "      <td>S1901_C04_004E</td>\n",
       "      <td>88</td>\n",
       "      <td>Both</td>\n",
       "      <td>all ages</td>\n",
       "      <td>Income In The Past 12 Months (in 2018 Inflatio...</td>\n",
       "      <td>NF3</td>\n",
       "      <td>Nonfamily Household Income $15,000 to $24,999</td>\n",
       "      <td>5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>[]</td>\n",
       "      <td>6</td>\n",
       "      <td>S1901_C01_003E</td>\n",
       "      <td>92</td>\n",
       "      <td>Both</td>\n",
       "      <td>all ages</td>\n",
       "      <td>Income In The Past 12 Months (in 2018 Inflatio...</td>\n",
       "      <td>F2</td>\n",
       "      <td>Family Household Income $10,000 to $14,999</td>\n",
       "      <td>5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>[   1    2    3    4    5    6    7    8    9 ...</td>\n",
       "      <td>23</td>\n",
       "      <td>S1901_C04_010E</td>\n",
       "      <td>96</td>\n",
       "      <td>Both</td>\n",
       "      <td>all ages</td>\n",
       "      <td>Income In The Past 12 Months (in 2018 Inflatio...</td>\n",
       "      <td>NF9</td>\n",
       "      <td>Nonfamily Household Income $150,000 to $199,999</td>\n",
       "      <td>5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>[6782 6783 6784 6785 6786 6787 6788 6789 6790 ...</td>\n",
       "      <td>16</td>\n",
       "      <td>S1901_C04_003E</td>\n",
       "      <td>96</td>\n",
       "      <td>Both</td>\n",
       "      <td>all ages</td>\n",
       "      <td>Income In The Past 12 Months (in 2018 Inflatio...</td>\n",
       "      <td>NF2</td>\n",
       "      <td>Nonfamily Household Income $10,000 to $14,999</td>\n",
       "      <td>5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>[ 8284  8285  8286  8287  8288  8289  8290  82...</td>\n",
       "      <td>13</td>\n",
       "      <td>S1901_C01_010E</td>\n",
       "      <td>96</td>\n",
       "      <td>Both</td>\n",
       "      <td>all ages</td>\n",
       "      <td>Income In The Past 12 Months (in 2018 Inflatio...</td>\n",
       "      <td>F9</td>\n",
       "      <td>Family Household Income $150,000 to $199,999</td>\n",
       "      <td>5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>[13123 13124 13125 13126 13127 13128 13129 131...</td>\n",
       "      <td>24</td>\n",
       "      <td>S1901_C04_011E</td>\n",
       "      <td>98</td>\n",
       "      <td>Both</td>\n",
       "      <td>all ages</td>\n",
       "      <td>Income In The Past 12 Months (in 2018 Inflatio...</td>\n",
       "      <td>NF10</td>\n",
       "      <td>Nonfamily Household Income $200,000 or more</td>\n",
       "      <td>5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>[]</td>\n",
       "      <td>14</td>\n",
       "      <td>S1901_C01_011E</td>\n",
       "      <td>101</td>\n",
       "      <td>Both</td>\n",
       "      <td>all ages</td>\n",
       "      <td>Income In The Past 12 Months (in 2018 Inflatio...</td>\n",
       "      <td>F10</td>\n",
       "      <td>Family Household Income $200,000 or more</td>\n",
       "      <td>5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 ...</td>\n",
       "      <td>7</td>\n",
       "      <td>S1901_C01_004E</td>\n",
       "      <td>104</td>\n",
       "      <td>Both</td>\n",
       "      <td>all ages</td>\n",
       "      <td>Income In The Past 12 Months (in 2018 Inflatio...</td>\n",
       "      <td>F3</td>\n",
       "      <td>Family Household Income $15,000 to $24,999</td>\n",
       "      <td>5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>[66 67 68 69 70 71 72]</td>\n",
       "      <td>21</td>\n",
       "      <td>S1901_C04_008E</td>\n",
       "      <td>107</td>\n",
       "      <td>Both</td>\n",
       "      <td>all ages</td>\n",
       "      <td>Income In The Past 12 Months (in 2018 Inflatio...</td>\n",
       "      <td>NF7</td>\n",
       "      <td>Nonfamily Household Income $75,000 to $99,999</td>\n",
       "      <td>5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>[73]</td>\n",
       "      <td>20</td>\n",
       "      <td>S1901_C04_007E</td>\n",
       "      <td>113</td>\n",
       "      <td>Both</td>\n",
       "      <td>all ages</td>\n",
       "      <td>Income In The Past 12 Months (in 2018 Inflatio...</td>\n",
       "      <td>NF6</td>\n",
       "      <td>Nonfamily Household Income $50,000 to $74,999</td>\n",
       "      <td>5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>[74 75 76 77 78 79 80 81 82 83 84 85]</td>\n",
       "      <td>11</td>\n",
       "      <td>S1901_C01_008E</td>\n",
       "      <td>113</td>\n",
       "      <td>Both</td>\n",
       "      <td>all ages</td>\n",
       "      <td>Income In The Past 12 Months (in 2018 Inflatio...</td>\n",
       "      <td>F7</td>\n",
       "      <td>Family Household Income $75,000 to $99,999</td>\n",
       "      <td>5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>[86 87 88]</td>\n",
       "      <td>10</td>\n",
       "      <td>S1901_C01_007E</td>\n",
       "      <td>131</td>\n",
       "      <td>Both</td>\n",
       "      <td>all ages</td>\n",
       "      <td>Income In The Past 12 Months (in 2018 Inflatio...</td>\n",
       "      <td>F6</td>\n",
       "      <td>Family Household Income $50,000 to $74,999</td>\n",
       "      <td>5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>[89 90 91 92]</td>\n",
       "      <td>5</td>\n",
       "      <td>S1901_C01_002E</td>\n",
       "      <td>131</td>\n",
       "      <td>Both</td>\n",
       "      <td>all ages</td>\n",
       "      <td>Income In The Past 12 Months (in 2018 Inflatio...</td>\n",
       "      <td>F1</td>\n",
       "      <td>Family Household Income Less than $10,000</td>\n",
       "      <td>5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>[93 94 95 96]</td>\n",
       "      <td>12</td>\n",
       "      <td>S1901_C01_009E</td>\n",
       "      <td>170</td>\n",
       "      <td>Both</td>\n",
       "      <td>all ages</td>\n",
       "      <td>Income In The Past 12 Months (in 2018 Inflatio...</td>\n",
       "      <td>F8</td>\n",
       "      <td>Family Household Income $100,000 to $149,999</td>\n",
       "      <td>5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>[]</td>\n",
       "      <td>15</td>\n",
       "      <td>S1901_C04_002E</td>\n",
       "      <td>174</td>\n",
       "      <td>Both</td>\n",
       "      <td>all ages</td>\n",
       "      <td>Income In The Past 12 Months (in 2018 Inflatio...</td>\n",
       "      <td>NF1</td>\n",
       "      <td>Nonfamily Household Income Less than $10,000</td>\n",
       "      <td>5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>[]</td>\n",
       "      <td>22</td>\n",
       "      <td>S1901_C04_009E</td>\n",
       "      <td>186</td>\n",
       "      <td>Both</td>\n",
       "      <td>all ages</td>\n",
       "      <td>Income In The Past 12 Months (in 2018 Inflatio...</td>\n",
       "      <td>NF8</td>\n",
       "      <td>Nonfamily Household Income $100,000 to $149,999</td>\n",
       "      <td>5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>[97 98]</td>\n",
       "      <td>4</td>\n",
       "      <td>S1601_C01_018E</td>\n",
       "      <td>612</td>\n",
       "      <td>Both</td>\n",
       "      <td>18 to 64 years</td>\n",
       "      <td>Language Spoken At Home</td>\n",
       "      <td>Other languages</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18, 19, 20, 21, 22, 23, 24, 25,26, 27, 28, 29,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>[ 99 100 101]</td>\n",
       "      <td>2</td>\n",
       "      <td>S1601_C01_010E</td>\n",
       "      <td>2693</td>\n",
       "      <td>Both</td>\n",
       "      <td>18 to 64 years</td>\n",
       "      <td>Language Spoken At Home</td>\n",
       "      <td>Other Indo-European languages</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18, 19, 20, 21, 22, 23, 24, 25,26, 27, 28, 29,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>[102 103 104]</td>\n",
       "      <td>3</td>\n",
       "      <td>S1601_C01_014E</td>\n",
       "      <td>5218</td>\n",
       "      <td>Both</td>\n",
       "      <td>18 to 64 years</td>\n",
       "      <td>Language Spoken At Home</td>\n",
       "      <td>Asian and Pacific Island languages</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18, 19, 20, 21, 22, 23, 24, 25,26, 27, 28, 29,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>[105 106 107]</td>\n",
       "      <td>1</td>\n",
       "      <td>S1601_C01_006E</td>\n",
       "      <td>5841</td>\n",
       "      <td>Both</td>\n",
       "      <td>18 to 64 years</td>\n",
       "      <td>Language Spoken At Home</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18, 19, 20, 21, 22, 23, 24, 25,26, 27, 28, 29,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>[108 109 110 111 112 113]</td>\n",
       "      <td>28</td>\n",
       "      <td>S1501_C03_018E</td>\n",
       "      <td>6781</td>\n",
       "      <td>Male</td>\n",
       "      <td>25 to 34 years</td>\n",
       "      <td>Educational Attainment</td>\n",
       "      <td>Bachelor's degree or higher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25,26, 27, 28, 29, 30, 31, 32, 33, 34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>[]</td>\n",
       "      <td>27</td>\n",
       "      <td>S1501_C03_017E</td>\n",
       "      <td>8283</td>\n",
       "      <td>Male</td>\n",
       "      <td>25 to 34 years</td>\n",
       "      <td>Educational Attainment</td>\n",
       "      <td>High school graduate or higher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25,26, 27, 28, 29, 30, 31, 32, 33, 34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>[114 115 116 117 118 119 120 121 122 123 124 1...</td>\n",
       "      <td>26</td>\n",
       "      <td>S1501_C01_018E</td>\n",
       "      <td>13122</td>\n",
       "      <td>Both</td>\n",
       "      <td>25 to 34 years</td>\n",
       "      <td>Educational Attainment</td>\n",
       "      <td>Bachelor's degree or higher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25,26, 27, 28, 29, 30, 31, 32, 33, 34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>[]</td>\n",
       "      <td>25</td>\n",
       "      <td>S1501_C01_017E</td>\n",
       "      <td>15576</td>\n",
       "      <td>Both</td>\n",
       "      <td>25 to 34 years</td>\n",
       "      <td>Educational Attainment</td>\n",
       "      <td>High school graduate or higher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25,26, 27, 28, 29, 30, 31, 32, 33, 34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>[132 133 134 135 136 137 138 139 140 141 142 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>S1603_C02_003E</td>\n",
       "      <td>24936</td>\n",
       "      <td>Both</td>\n",
       "      <td>18 to 64 years</td>\n",
       "      <td>Language Spoken At Home</td>\n",
       "      <td>Speak Only English at Home</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18, 19, 20, 21, 22, 23, 24, 25,26, 27, 28, 29,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index_x                                 sum_in_area_ranges  index_y  \\\n",
       "0         0                                                 []       29   \n",
       "1         1  [  1   2   3   4   5   6   7   8   9  10  11  ...       18   \n",
       "2         2  [ 613  614  615  616  617  618  619  620  621 ...       19   \n",
       "3         3  [2694 2695 2696 2697 2698 2699 2700 2701 2702 ...        8   \n",
       "4         4  [5219 5220 5221 5222 5223 5224 5225 5226 5227 ...        9   \n",
       "5         5  [ 5842  5843  5844  5845  5846  5847  5848  58...       17   \n",
       "6         6                                                 []        6   \n",
       "7         7  [   1    2    3    4    5    6    7    8    9 ...       23   \n",
       "8         8  [6782 6783 6784 6785 6786 6787 6788 6789 6790 ...       16   \n",
       "9         9  [ 8284  8285  8286  8287  8288  8289  8290  82...       13   \n",
       "10       10  [13123 13124 13125 13126 13127 13128 13129 131...       24   \n",
       "11       11                                                 []       14   \n",
       "12       12  [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 ...        7   \n",
       "13       13                             [66 67 68 69 70 71 72]       21   \n",
       "14       14                                               [73]       20   \n",
       "15       15              [74 75 76 77 78 79 80 81 82 83 84 85]       11   \n",
       "16       16                                         [86 87 88]       10   \n",
       "17       17                                      [89 90 91 92]        5   \n",
       "18       18                                      [93 94 95 96]       12   \n",
       "19       19                                                 []       15   \n",
       "20       20                                                 []       22   \n",
       "21       21                                            [97 98]        4   \n",
       "22       22                                      [ 99 100 101]        2   \n",
       "23       23                                      [102 103 104]        3   \n",
       "24       24                                      [105 106 107]        1   \n",
       "25       25                          [108 109 110 111 112 113]       28   \n",
       "26       26                                                 []       27   \n",
       "27       27  [114 115 116 117 118 119 120 121 122 123 124 1...       26   \n",
       "28       28                                                 []       25   \n",
       "29       29  [132 133 134 135 136 137 138 139 140 141 142 1...        0   \n",
       "\n",
       "         variables  sum_in_area   sex       age_group  \\\n",
       "0   Baseline_Value            0   NaN             NaN   \n",
       "1   S1901_C04_005E           65  Both        all ages   \n",
       "2   S1901_C04_006E           72  Both        all ages   \n",
       "3   S1901_C01_005E           73  Both        all ages   \n",
       "4   S1901_C01_006E           85  Both        all ages   \n",
       "5   S1901_C04_004E           88  Both        all ages   \n",
       "6   S1901_C01_003E           92  Both        all ages   \n",
       "7   S1901_C04_010E           96  Both        all ages   \n",
       "8   S1901_C04_003E           96  Both        all ages   \n",
       "9   S1901_C01_010E           96  Both        all ages   \n",
       "10  S1901_C04_011E           98  Both        all ages   \n",
       "11  S1901_C01_011E          101  Both        all ages   \n",
       "12  S1901_C01_004E          104  Both        all ages   \n",
       "13  S1901_C04_008E          107  Both        all ages   \n",
       "14  S1901_C04_007E          113  Both        all ages   \n",
       "15  S1901_C01_008E          113  Both        all ages   \n",
       "16  S1901_C01_007E          131  Both        all ages   \n",
       "17  S1901_C01_002E          131  Both        all ages   \n",
       "18  S1901_C01_009E          170  Both        all ages   \n",
       "19  S1901_C04_002E          174  Both        all ages   \n",
       "20  S1901_C04_009E          186  Both        all ages   \n",
       "21  S1601_C01_018E          612  Both  18 to 64 years   \n",
       "22  S1601_C01_010E         2693  Both  18 to 64 years   \n",
       "23  S1601_C01_014E         5218  Both  18 to 64 years   \n",
       "24  S1601_C01_006E         5841  Both  18 to 64 years   \n",
       "25  S1501_C03_018E         6781  Male  25 to 34 years   \n",
       "26  S1501_C03_017E         8283  Male  25 to 34 years   \n",
       "27  S1501_C01_018E        13122  Both  25 to 34 years   \n",
       "28  S1501_C01_017E        15576  Both  25 to 34 years   \n",
       "29  S1603_C02_003E        24936  Both  18 to 64 years   \n",
       "\n",
       "                                       variable_group  \\\n",
       "0                                      Baseline_Group   \n",
       "1   Income In The Past 12 Months (in 2018 Inflatio...   \n",
       "2   Income In The Past 12 Months (in 2018 Inflatio...   \n",
       "3   Income In The Past 12 Months (in 2018 Inflatio...   \n",
       "4   Income In The Past 12 Months (in 2018 Inflatio...   \n",
       "5   Income In The Past 12 Months (in 2018 Inflatio...   \n",
       "6   Income In The Past 12 Months (in 2018 Inflatio...   \n",
       "7   Income In The Past 12 Months (in 2018 Inflatio...   \n",
       "8   Income In The Past 12 Months (in 2018 Inflatio...   \n",
       "9   Income In The Past 12 Months (in 2018 Inflatio...   \n",
       "10  Income In The Past 12 Months (in 2018 Inflatio...   \n",
       "11  Income In The Past 12 Months (in 2018 Inflatio...   \n",
       "12  Income In The Past 12 Months (in 2018 Inflatio...   \n",
       "13  Income In The Past 12 Months (in 2018 Inflatio...   \n",
       "14  Income In The Past 12 Months (in 2018 Inflatio...   \n",
       "15  Income In The Past 12 Months (in 2018 Inflatio...   \n",
       "16  Income In The Past 12 Months (in 2018 Inflatio...   \n",
       "17  Income In The Past 12 Months (in 2018 Inflatio...   \n",
       "18  Income In The Past 12 Months (in 2018 Inflatio...   \n",
       "19  Income In The Past 12 Months (in 2018 Inflatio...   \n",
       "20  Income In The Past 12 Months (in 2018 Inflatio...   \n",
       "21                            Language Spoken At Home   \n",
       "22                            Language Spoken At Home   \n",
       "23                            Language Spoken At Home   \n",
       "24                            Language Spoken At Home   \n",
       "25                             Educational Attainment   \n",
       "26                             Educational Attainment   \n",
       "27                             Educational Attainment   \n",
       "28                             Educational Attainment   \n",
       "29                            Language Spoken At Home   \n",
       "\n",
       "                         variable_name  \\\n",
       "0                                  NaN   \n",
       "1                                  NF4   \n",
       "2                                  NF5   \n",
       "3                                   F4   \n",
       "4                                   F5   \n",
       "5                                  NF3   \n",
       "6                                   F2   \n",
       "7                                  NF9   \n",
       "8                                  NF2   \n",
       "9                                   F9   \n",
       "10                                NF10   \n",
       "11                                 F10   \n",
       "12                                  F3   \n",
       "13                                 NF7   \n",
       "14                                 NF6   \n",
       "15                                  F7   \n",
       "16                                  F6   \n",
       "17                                  F1   \n",
       "18                                  F8   \n",
       "19                                 NF1   \n",
       "20                                 NF8   \n",
       "21                     Other languages   \n",
       "22       Other Indo-European languages   \n",
       "23  Asian and Pacific Island languages   \n",
       "24                             Spanish   \n",
       "25         Bachelor's degree or higher   \n",
       "26      High school graduate or higher   \n",
       "27         Bachelor's degree or higher   \n",
       "28      High school graduate or higher   \n",
       "29          Speak Only English at Home   \n",
       "\n",
       "                               variable_description  \\\n",
       "0                                               NaN   \n",
       "1     Nonfamily Household Income $25,000 to $34,999   \n",
       "2     Nonfamily Household Income $35,000 to $49,999   \n",
       "3        Family Household Income $25,000 to $34,999   \n",
       "4        Family Household Income $35,000 to $49,999   \n",
       "5     Nonfamily Household Income $15,000 to $24,999   \n",
       "6        Family Household Income $10,000 to $14,999   \n",
       "7   Nonfamily Household Income $150,000 to $199,999   \n",
       "8     Nonfamily Household Income $10,000 to $14,999   \n",
       "9      Family Household Income $150,000 to $199,999   \n",
       "10      Nonfamily Household Income $200,000 or more   \n",
       "11         Family Household Income $200,000 or more   \n",
       "12       Family Household Income $15,000 to $24,999   \n",
       "13    Nonfamily Household Income $75,000 to $99,999   \n",
       "14    Nonfamily Household Income $50,000 to $74,999   \n",
       "15       Family Household Income $75,000 to $99,999   \n",
       "16       Family Household Income $50,000 to $74,999   \n",
       "17        Family Household Income Less than $10,000   \n",
       "18     Family Household Income $100,000 to $149,999   \n",
       "19     Nonfamily Household Income Less than $10,000   \n",
       "20  Nonfamily Household Income $100,000 to $149,999   \n",
       "21                                              NaN   \n",
       "22                                              NaN   \n",
       "23                                              NaN   \n",
       "24                                              NaN   \n",
       "25                                              NaN   \n",
       "26                                              NaN   \n",
       "27                                              NaN   \n",
       "28                                              NaN   \n",
       "29                                              NaN   \n",
       "\n",
       "                                                 ages  \n",
       "0                                                 NaN  \n",
       "1   5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...  \n",
       "2   5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...  \n",
       "3   5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...  \n",
       "4   5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...  \n",
       "5   5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...  \n",
       "6   5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...  \n",
       "7   5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...  \n",
       "8   5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...  \n",
       "9   5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...  \n",
       "10  5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...  \n",
       "11  5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...  \n",
       "12  5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...  \n",
       "13  5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...  \n",
       "14  5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...  \n",
       "15  5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...  \n",
       "16  5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...  \n",
       "17  5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...  \n",
       "18  5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...  \n",
       "19  5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...  \n",
       "20  5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,...  \n",
       "21  18, 19, 20, 21, 22, 23, 24, 25,26, 27, 28, 29,...  \n",
       "22  18, 19, 20, 21, 22, 23, 24, 25,26, 27, 28, 29,...  \n",
       "23  18, 19, 20, 21, 22, 23, 24, 25,26, 27, 28, 29,...  \n",
       "24  18, 19, 20, 21, 22, 23, 24, 25,26, 27, 28, 29,...  \n",
       "25              25,26, 27, 28, 29, 30, 31, 32, 33, 34  \n",
       "26              25,26, 27, 28, 29, 30, 31, 32, 33, 34  \n",
       "27              25,26, 27, 28, 29, 30, 31, 32, 33, 34  \n",
       "28              25,26, 27, 28, 29, 30, 31, 32, 33, 34  \n",
       "29  18, 19, 20, 21, 22, 23, 24, 25,26, 27, 28, 29,...  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range_table_cumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "household_income = df[(df[\"variable_group\"].str.contains('Income'))]\n",
    "household_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "household_income_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_base_text():\n",
    "    for item,i in enumerate(range_table_cumulative.index):\n",
    "        global descriptors, result, result_variable, result_text\n",
    "        descriptors=[]\n",
    "        \n",
    "        if range_table_cumulative[\"sum_ranges\"].str.contains(sum_for_percentile_language).any():\n",
    "            result = range_table_cumulative[range_table_cumulative['sum_ranges'].str.contains(sum_for_percentile_language)]\n",
    "            \n",
    "        elif range_table_cumulative[\"sum_ranges\"].str.contains(sum_for_percentile_education).any():\n",
    "            result = range_table_cumulative[range_table_cumulative['sum_ranges'].str.contains(sum_for_percentile_education)]\n",
    "#     else:\n",
    "#         print(\"Error!\")\n",
    "        result_variable = result[\"variables\"].values[0]\n",
    "\n",
    "        #So returning the data dictionary for this \n",
    "        dict_result = data_dict[data_dict[\"variables\"].str.contains(result_variable)]\n",
    "        result_text = dict_result[\"variable_name\"].values[0]\n",
    "\n",
    "        #then append to empty dataframe that will have the data for text generation\n",
    "        descriptors.append([result_text])\n",
    "            \n",
    "generate_base_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "household_income_range_string = \",\".join(household_income_range.astype(str))\n",
    "# test = range_table.loc[range_table[\"sum_in_area_ranges\"].str.contains(household_income_range_string)]\n",
    "range_table[\"sum_in_area_ranges\"].astype(str).str.contains(household_income_range_string)\n",
    "# type(household_income_range_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptors ... so need to fix this. \n",
    "# need to actually make this loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generation_button = Button(description=\"Generate Text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_text():\n",
    "    percentile_string = \"This description represents the top \"+ str(selected_percentile.value) + \"% of this area's residents.\"\n",
    "    print(percentile_string)\n",
    "    \n",
    "    if (selected_gender.value == \"Male\"):\n",
    "        gender_text = \"she\"\n",
    "    elif (selected_gender.value == \"Female\"):\n",
    "        gender_text = \"he\"\n",
    "    elif (selected_gender.value == \"Both\"):\n",
    "        gender_text = \"they\"\n",
    "        \n",
    "    if (selected_age.value == \"5 to 17 Years\") & (selected_gender.value == \"Total Population\"):\n",
    "        subject_description = \"As a young woman, you \"\n",
    "    else:\n",
    "        subject_description = \"As a young woman, you \"\n",
    "    \n",
    "    if (result_text == \"Speak a Language other than English at Home\"):\n",
    "        language_text = \"In addition to english, \" + gender_text + \" speaks \" + + \" at home.\"\n",
    "#     This young woman is well-educated and has at least a bachelorâ€™s degree. In addition to English, she speaks Spanish at home. She lives with her family, and her household is quite wealthy. She drives to work alone on her short commute. \n",
    "\n",
    "    global resident_string\n",
    "    resident_string = language_text + percentile_string\n",
    "    \n",
    "    with output:\n",
    "        display(resident_string)\n",
    "    \n",
    "replace_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resident_string = \"help\"\n",
    "\n",
    "#TEXT GENERATION\n",
    "def text_generation(b):\n",
    "    output.clear_output()\n",
    "    data_output.clear_output()\n",
    "    \n",
    "    user_selection()\n",
    "    descriptor_generation()\n",
    "    range_per_variable_calculation()\n",
    "    generate_base_text()\n",
    "    \n",
    "    replace_text()    \n",
    "    \n",
    "text_generation_button.on_click(text_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def display_dashboard():\n",
    "    user_selection()\n",
    "    \n",
    "    item_layout = widgets.Layout(margin='0 0 10px 0')\n",
    "    \n",
    "    with output:\n",
    "        display(resident_string)\n",
    "    with data_output:\n",
    "        display(range_table)\n",
    "        \n",
    "    input_widgets = widgets.VBox(\n",
    "        [selected_age, selected_gender, selected_percentile, text_generation_button],\n",
    "        layout=item_layout)\n",
    "    \n",
    "    tab = widgets.Tab([output, data_output],\n",
    "        layout=item_layout)\n",
    "    tab.set_title(0, 'Narrative')\n",
    "    tab.set_title(1, 'Dataset Exploration')\n",
    "    \n",
    "    dashboard = widgets.VBox([input_widgets, tab])\n",
    "    display(dashboard)\n",
    "\n",
    "display_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# widget_control = WidgetControl(widget=text_generation_button, position='topright')\n",
    "# m.add_control(widget_control)\n",
    "\n",
    "# m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
