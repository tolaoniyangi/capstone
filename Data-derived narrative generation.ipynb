{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point, Polygon\n",
    "import random\n",
    "from fiona.crs import from_epsg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib, json, requests, geojson\n",
    "import googlemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyleaflet import Map, GeoData, GeoJSON, basemaps, basemap_to_tiles, Icon, Circle, Marker, LayerGroup, WidgetControl\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Button, Layout\n",
    "from IPython.display import display, clear_output, Markdown as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need this to stop numpy from returning truncated arrays \n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "# for automatic linebreaks and multi-line cells\n",
    "pd.options.display.max_colwidth = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drawing basic map\n",
    "center = (40.7210907,-73.9877836)\n",
    "basemap = basemap_to_tiles(basemaps.CartoDB.Positron)\n",
    "\n",
    "m = Map(layers=(basemap, ), center=center, zoom=14, min_zoom = 7, max_zoom = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_location():       \n",
    "    global gdf, lat, lon\n",
    "    \n",
    "    lat = str(markerlocation[0])\n",
    "    lon = str(markerlocation[1])\n",
    "    \n",
    "    df2 = pd.DataFrame(markerlocation)\n",
    "    df=df2.transpose()\n",
    "    df.columns=['Latitude','Longitude']\n",
    "\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.Longitude, df.Latitude), crs='epsg:4326')\n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "draggable=False\n",
    "marker_opacity=0\n",
    "icon = Icon(icon_url='icon.png', icon_size=[15, 15])\n",
    "\n",
    "marker = Marker(location=center, draggable=draggable, icon=icon, opacity=marker_opacity)\n",
    "\n",
    "markerlocation = marker.location \n",
    "\n",
    "layer_group = LayerGroup(layers=(marker, ))\n",
    "m.add_layer(layer_group)\n",
    "   \n",
    "def update_marker(**kwargs):\n",
    "    \n",
    "    if kwargs.get('type') == 'click':\n",
    "        layer_group.clear_layers();\n",
    "        \n",
    "        marker = Marker(location=kwargs.get('coordinates'), draggable=draggable, icon=icon, opacity=marker_opacity, options=['rise_on_hover'])  \n",
    "        \n",
    "        global markerlocation\n",
    "        markerlocation = marker.location \n",
    "        \n",
    "        layer_group.add_layer(marker)\n",
    "    \n",
    "        draw_update_buffer(**kwargs)\n",
    "        \n",
    "        data_output.clear_output()\n",
    "        output.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_update_buffer(**kwargs):     \n",
    "    m.on_interaction(update_marker)\n",
    "    extract_location()\n",
    "    \n",
    "    global half_mi\n",
    "    half_mi=gdf.copy()\n",
    "    half_mi['geometry'] = half_mi.geometry.buffer(.004,  cap_style=1, join_style=1)\n",
    "\n",
    "    map_extent = gdf.copy()\n",
    "    map_extent['geometry'] = map_extent.buffer(1,  cap_style=1, join_style=1)\n",
    "\n",
    "    diff = gpd.overlay(map_extent, half_mi, how='difference')\n",
    "    \n",
    "    half_mi_difference = GeoData(geo_dataframe = diff,\n",
    "                       style={'color': \"black\", \\\n",
    "                              'fillColor': \"#000000\", \\\n",
    "                              'fillOpacity': .2, \\\n",
    "                              'opacity': 1, \\\n",
    "                              'weight': 2},\n",
    "                       name = \"Test\", crs='epsg:4326')\n",
    "\n",
    "    layer_group.add_layer(half_mi_difference) \n",
    "\n",
    "draw_update_buffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_censustracts():\n",
    "    extract_location()\n",
    "    \n",
    "    bounding_box = half_mi.envelope\n",
    "    df = gpd.GeoDataFrame(gpd.GeoSeries(bounding_box), columns=['geometry'])\n",
    "    minx, miny, maxx, maxy = df.geometry.total_bounds\n",
    "    bounds = minx, miny, maxx, maxy\n",
    "\n",
    "    # census tracts link\n",
    "    endpoint = 'https://tigerweb.geo.census.gov/arcgis/rest/services/TIGERweb/Tracts_Blocks/MapServer/4/query'\n",
    "    s = requests.session()\n",
    "    s.params = {\n",
    "        'geometry': str(bounds),\n",
    "        'geometryType': 'esriGeometryEnvelope',\n",
    "        'inSR': 4326,\n",
    "        'spatialRel': 'esriSpatialRelIntersects',\n",
    "        'outFields': 'GEOID,STATE,COUNTY,TRACT,NAME,STGEOMETRY,OBJECTID',\n",
    "        'returnGeometry': True,\n",
    "        'f': 'geojson',        \n",
    "    }\n",
    "    start = 0\n",
    "    done = False\n",
    "    features = []\n",
    "    crs = None\n",
    "    while not done:\n",
    "        r = s.get(endpoint, params={\n",
    "            'resultOffset': start,\n",
    "            'resultRecordCount': 32,\n",
    "        })\n",
    "        censusgeo = geojson.loads(r.text)\n",
    "        newfeats = censusgeo.__geo_interface__['features']\n",
    "        if newfeats:\n",
    "            features.extend(newfeats)\n",
    "            crs=censusgeo.__geo_interface__['crs']\n",
    "            start += len(newfeats)\n",
    "#             print(\"Received\", len(newfeats), \"entries,\", start, \"total\")\n",
    "        else:\n",
    "            done = True\n",
    "    \n",
    "    global tracts\n",
    "    tracts = gpd.GeoDataFrame.from_features(features, crs=crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_acs():  \n",
    "    state = tracts[\"STATE\"].unique().tolist()\n",
    "    state = ', '.join(map(str, state)).replace(\" \", \"\")\n",
    "\n",
    "    tract = tracts[\"TRACT\"].unique().tolist()\n",
    "    tract = ', '.join(map(str, tract)).replace(\" \", \"\") \n",
    "\n",
    "    county = tracts[\"COUNTY\"].unique().tolist()\n",
    "    county = ', '.join(map(str, county)).replace(\" \", \"\") \n",
    "\n",
    "    api_key = '9330dc4bf086a84f19fb412bb15f232507301de6'\n",
    "    acs_url = f'https://api.census.gov/data/2018/acs/acs5/subject/'\n",
    "    \n",
    "    global acs_variables\n",
    "    acs_variables_initial = 'S1603_C02_002E,S1603_C02_003E,S1603_C02_004E,S1603_C04_002E,S1603_C04_003E,S1603_C04_004E,S1601_C01_005E,S1601_C01_006E,S1601_C01_007E,S1601_C01_009E,S1601_C01_010E,S1601_C01_011E,S1601_C01_013E,S1601_C01_014E,S1601_C01_015E,S1601_C01_017E,S1601_C01_018E,S1601_C01_019E,S1901_C01_002E,S1901_C01_003E,S1901_C01_004E,S1901_C01_005E,S1901_C01_006E,S1901_C01_007E,S1901_C01_008E,S1901_C01_009E,S1901_C01_010E,S1901_C01_011E,S1901_C04_002E,S1901_C04_003E,S1901_C04_004E,S1901_C04_005E,S1901_C04_006E,S1901_C04_007E,S1901_C04_008E,S1901_C04_009E,S1901_C04_010E,S1901_C04_011E'\n",
    "    acs_variables_additional = 'S1501_C01_002E,S1501_C01_004E,S1501_C01_003E,S1501_C01_005E,S1501_C01_017E,S1501_C01_018E,S1501_C01_020E,S1501_C01_021E,S1501_C01_023E,S1501_C01_024E,S1501_C01_025E,S1501_C01_026E,S1501_C03_002E,S1501_C03_003E,S1501_C03_004E,S1501_C03_005E,S1501_C03_017E,S1501_C03_018E,S1501_C03_020E,S1501_C03_021E,S1501_C03_023E,S1501_C03_024E,S1501_C03_026E,S1501_C03_027E,S1501_C05_002E,S1501_C05_003E,S1501_C05_004E,S1501_C05_005E,S1501_C05_017E,S1501_C05_018E,S1501_C05_020E,S1501_C05_021E,S1501_C05_023E,S1501_C05_024E,S1501_C05_026E,S1501_C05_027E,S1401_C01_030E,S1401_C01_032E,S1401_C01_034E,S1101_C01_003E,S1101_C05_001E'\n",
    "    acs_variables = acs_variables_initial + \",\" + acs_variables_additional\n",
    "    \n",
    "    get_acs_initial = f'{acs_url}?&get={acs_variables_initial}&for=tract:{tract}&in=state:{state}%20county:{county}&key={api_key}'\n",
    "    get_acs_additional = f'{acs_url}?&get={acs_variables_additional}&for=tract:{tract}&in=state:{state}%20county:{county}&key={api_key}'\n",
    "\n",
    "    data_acs_initial=requests.get(get_acs_initial).json()\n",
    "    data_acs_additional=requests.get(get_acs_additional).json()\n",
    "    \n",
    "    global acs\n",
    "    acs_initial=pd.DataFrame(data_acs_initial[1:], columns=data_acs_initial[0])\n",
    "    acs_additional=pd.DataFrame(data_acs_additional[1:], columns=data_acs_additional[0])\n",
    "\n",
    "    acs=pd.merge(acs_initial, acs_additional, on='tract', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_combine_census_and_geographic_data():\n",
    "    import_censustracts()\n",
    "    download_acs()\n",
    "    \n",
    "    global acs_site_sum, acs_site\n",
    "    tracts[\"area\"]=tracts.area\n",
    "    acs_tracts = pd.merge(tracts, acs, left_on='TRACT', right_on='tract', how='left')\n",
    "    \n",
    "    acs_site = gpd.overlay(half_mi, acs_tracts, how='intersection')\n",
    "    acs_site[\"area_clipped\"]=acs_site.area \n",
    "    acs_site[\"ratio\"] = acs_site[\"area_clipped\"]/acs_site[\"area\"]\n",
    "    \n",
    "    cols = acs_variables.split(\",\")\n",
    "    acs_site[cols] = acs_site[cols].apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "    \n",
    "    temp_df = acs_site[cols]    \n",
    "    temp_df = temp_df.mul(acs_site.ratio, 0)\n",
    "    acs_site.update(temp_df)\n",
    "\n",
    "    acs_site_sum = pd.DataFrame(acs_site[cols].sum())\n",
    "\n",
    "    acs_site_sum.reset_index(inplace=True)\n",
    "    acs_site_sum.columns = ['variables', 'sum_in_area']\n",
    "    acs_site_sum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age_group</th>\n",
       "      <th>variable_group</th>\n",
       "      <th>variables</th>\n",
       "      <th>variable_name</th>\n",
       "      <th>ages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Male Female Both</td>\n",
       "      <td>5 to 17 years</td>\n",
       "      <td>Language Spoken At Home</td>\n",
       "      <td>S1603_C02_002E</td>\n",
       "      <td>Speak Only English at Home</td>\n",
       "      <td>5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Male Female Both</td>\n",
       "      <td>18 to 64 years</td>\n",
       "      <td>Language Spoken At Home</td>\n",
       "      <td>S1603_C02_003E</td>\n",
       "      <td>Speak Only English at Home</td>\n",
       "      <td>18, 19, 20, 21, 22, 23, 24, 25,26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Male Female Both</td>\n",
       "      <td>65 years and over</td>\n",
       "      <td>Language Spoken At Home</td>\n",
       "      <td>S1603_C02_004E</td>\n",
       "      <td>Speak Only English at Home</td>\n",
       "      <td>64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Male Female Both</td>\n",
       "      <td>5 to 17 years</td>\n",
       "      <td>Language Spoken At Home</td>\n",
       "      <td>S1601_C01_005E</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Male Female Both</td>\n",
       "      <td>18 to 64 years</td>\n",
       "      <td>Language Spoken At Home</td>\n",
       "      <td>S1601_C01_006E</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>18, 19, 20, 21, 22, 23, 24, 25,26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                sex           age_group           variable_group  \\\n",
       "0  Male Female Both       5 to 17 years  Language Spoken At Home   \n",
       "1  Male Female Both      18 to 64 years  Language Spoken At Home   \n",
       "2  Male Female Both  65 years and over   Language Spoken At Home   \n",
       "3  Male Female Both       5 to 17 years  Language Spoken At Home   \n",
       "4  Male Female Both      18 to 64 years  Language Spoken At Home   \n",
       "\n",
       "        variables               variable_name  \\\n",
       "0  S1603_C02_002E  Speak Only English at Home   \n",
       "1  S1603_C02_003E  Speak Only English at Home   \n",
       "2  S1603_C02_004E  Speak Only English at Home   \n",
       "3  S1601_C01_005E                     Spanish   \n",
       "4  S1601_C01_006E                     Spanish   \n",
       "\n",
       "                                                                                                                                                                                        ages  \n",
       "0                                                                                                                                              5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17  \n",
       "1  18, 19, 20, 21, 22, 23, 24, 25,26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64  \n",
       "2                                        64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100  \n",
       "3                                                                                                                                              5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17  \n",
       "4  18, 19, 20, 21, 22, 23, 24, 25,26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = pd.read_csv(\"data-dictionary.csv\")\n",
    "data_dict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL = 'ALL'\n",
    "def user_options_sorted_values_plus_ALL(array):\n",
    "    unique = array.unique().tolist()\n",
    "    unique.sort()\n",
    "    unique.insert(0, ALL)\n",
    "    unique.remove('Both')\n",
    "    unique.remove('Male Female Both')\n",
    "    return unique\n",
    "\n",
    "def user_options_sorted_values(array):\n",
    "    unique = array.unique().tolist()\n",
    "    unique.sort()\n",
    "    return unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def user_selection():\n",
    "\n",
    "    global selected_age, selected_gender, selected_percentile, text_generation_button, selection_filter, variable_inputs\n",
    "#     selected_age = widgets.Dropdown(options = user_options_sorted_values(data_dict.age_group),\\\n",
    "#                                     value = \"5 to 17 Years\")\n",
    "    selected_age = widgets.BoundedIntText(min=5, max=99, value=25, step=1, description='AGE:')\n",
    "    selected_age_str= str(selected_age.value)\n",
    "    \n",
    "    selected_gender = widgets.ToggleButtons(options = user_options_sorted_values_plus_ALL(data_dict.sex),\\\n",
    "                                            value = \"Male\",\\\n",
    "                                            description='SEX:', \\\n",
    "                                            disabled=False, button_style='', )\n",
    "#     selected_gender.style.font_weight = 'bold'\n",
    "    \n",
    "    selected_percentile = widgets.IntSlider(min=0, max=100, step=10, value=50, description='Percentile:',)\n",
    "    \n",
    "    if (selected_gender.value == 'ALL'):\n",
    "        selection_filter = data_dict[(data_dict.ages.str.contains(selected_age_str)) & \\\n",
    "                              (data_dict.sex.str.contains('Both'))]\n",
    "        \n",
    "    else:     \n",
    "        selection_filter = data_dict[(data_dict.ages.str.contains(selected_age_str)) & \\\n",
    "                              (data_dict.sex.str.contains(selected_gender.value))]\n",
    "                         \n",
    "    list_of_variable_inputs = selection_filter[\"variables\"].values[0:]\n",
    "    variable_inputs = ', '.join(list_of_variable_inputs).replace(\" \", \"\")\n",
    "    variable_inputs = variable_inputs.split(',')\n",
    "        \n",
    "user_selection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection_filtering(age_group, sex):\n",
    "    \n",
    "    selected_age_str= str(selected_age.value)\n",
    "\n",
    "    if (selected_gender.value == 'ALL'):\n",
    "        selection_filter = data_dict[(data_dict.ages.str.contains(selected_age_str)) & \\\n",
    "                          (data_dict.sex.str.contains('Both'))]\n",
    "\n",
    "    else:     \n",
    "        selection_filter = data_dict[(data_dict.ages.str.contains(selected_age_str)) & \\\n",
    "                          (data_dict.sex.str.contains(selected_gender.value))]\n",
    "\n",
    "    list_of_variable_inputs = selection_filter[\"variables\"].values[0:]\n",
    "    variable_inputs = ', '.join(list_of_variable_inputs).replace(\" \", \"\")\n",
    "    variable_inputs = variable_inputs.split(',')        \n",
    "    \n",
    "    data_output.clear_output()\n",
    "    output.clear_output()\n",
    "#     tab.layout.display = 'none'\n",
    "\n",
    "def selected_age_eventhandler(change):\n",
    "    selection_filtering(change.new, selected_age.value)\n",
    "#     tab.layout.display = 'none'\n",
    "def selected_gender_eventhandler(change):\n",
    "    selection_filtering(selected_gender.value, change.new)\n",
    "#     tab.layout.display = 'none'\n",
    "def selected_percentile_eventhandler(change):\n",
    "    selection_filtering(selected_percentile.value, change.new)\n",
    "#     tab.layout.display = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_demographics_for_selection():\n",
    "  \n",
    "    global percentile_input, data\n",
    "\n",
    "    data = pd.merge(acs_site_sum.loc[acs_site_sum['variables'].isin(variable_inputs)], \\\n",
    "                   selection_filter, how=\"outer\", on=\"variables\")    \n",
    "    data[\"sum_in_area\"] = data[\"sum_in_area\"].astype(int)\n",
    "    data.sort_values(\"sum_in_area\", axis = 0, ascending = True, inplace = True)\n",
    "\n",
    "    percentile_input = selected_percentile.value / 100\n",
    "    \n",
    "# split these up into the diff bins for different types of variable groups \n",
    "    global language, education, family_household_income, nonfamily_household_income, household_type\n",
    "\n",
    "    for item,i in enumerate(data):       \n",
    "        language = data[(data[\"variable_group\"].str.contains('Language'))]\n",
    "        education = data[(data[\"variable_group\"].str.contains('Educational Attainment'))]\n",
    "        family_household_income = data[(data[\"variable_group\"].str.contains('Family'))]\n",
    "        nonfamily_household_income = data[(data[\"variable_group\"].str.contains('Nonfamily'))]\n",
    "        household_type = data[(data[\"variable_group\"].str.contains('Households'))]\n",
    "#       travel_time_to_work = data[(data[\"variable_group\"].str.contains('Travel Time'))].sort_values(by='sum_in_area')\n",
    "        # means_of_transportation = data[(data[\"variable_group\"].str.contains('Means of Transportation'))].sort_values(by='sum_in_area')\n",
    "        \n",
    "#Calculate individual percentile values\n",
    "        global sum_for_percentile_language,sum_for_percentile_education,\\\n",
    "                sum_for_percentile_family_household_income,\\\n",
    "                sum_for_percentile_nonfamily_household_income, sum_for_percentile_household_type\n",
    "        \n",
    "        sum_for_percentile_language = language.sum_in_area.quantile(selected_percentile.value / 100).astype(int).astype(str)\n",
    "        sum_for_percentile_language = sum_for_percentile_language.replace(sum_for_percentile_language, \\\n",
    "                                language.sum_in_area.quantile(selected_percentile.value / 100).astype(int).astype(str))\n",
    "        \n",
    "        sum_for_percentile_education = education.sum_in_area.quantile(selected_percentile.value / 100).astype(int).astype(str)\n",
    "        sum_for_percentile_education = sum_for_percentile_education.replace(sum_for_percentile_education, \\\n",
    "                                education.sum_in_area.quantile(selected_percentile.value / 100).astype(int).astype(str))\n",
    "\n",
    "        sum_for_percentile_family_household_income = family_household_income.sum_in_area.quantile(selected_percentile.value / 100).astype(int).astype(str)\n",
    "        sum_for_percentile_family_household_income = sum_for_percentile_family_household_income.replace(sum_for_percentile_family_household_income, \\\n",
    "                                family_household_income.sum_in_area.quantile(selected_percentile.value / 100).astype(int).astype(str))\n",
    "        \n",
    "        sum_for_percentile_nonfamily_household_income = nonfamily_household_income.sum_in_area.quantile(selected_percentile.value / 100).astype(int).astype(str)\n",
    "        sum_for_percentile_nonfamily_household_income = sum_for_percentile_nonfamily_household_income.replace(sum_for_percentile_nonfamily_household_income, \\\n",
    "                                nonfamily_household_income.sum_in_area.quantile(selected_percentile.value / 100).astype(int).astype(str))        \n",
    "        \n",
    "        sum_for_percentile_household_type = household_type.sum_in_area.quantile(selected_percentile.value / 100).astype(int).astype(str)\n",
    "        sum_for_percentile_household_type = sum_for_percentile_household_type.replace(sum_for_percentile_household_type, \\\n",
    "                                household_type.sum_in_area.quantile(selected_percentile.value / 100).astype(int).astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tables_for_percentile_value():\n",
    "#generating new transposed table with only the two fields needed : variables and sum in area.\n",
    "#using other variables makes transposition weird\n",
    "    \n",
    "    global household_type_transposed, language_transposed, education_transposed, family_household_income_transposed, nonfamily_household_income_transposed,household_type_transposed\n",
    "\n",
    "    language_transposed = language.filter([\"variables\", \"sum_in_area\"]).T\n",
    "    language_transposed.columns = language_transposed.iloc[0]\n",
    "    language_transposed = language_transposed[1:]\n",
    "\n",
    "    education_transposed = education.filter([\"variables\", \"sum_in_area\"]).T\n",
    "    education_transposed.columns = education_transposed.iloc[0]\n",
    "    education_transposed = education_transposed[1:]\n",
    "\n",
    "    household_type_transposed = household_type.filter([\"variables\", \"sum_in_area\"]).T\n",
    "    household_type_transposed.columns = household_type_transposed.iloc[0]\n",
    "    household_type_transposed = household_type_transposed[1:]\n",
    "    \n",
    "    family_household_income_transposed = family_household_income.filter([\"variables\", \"sum_in_area\"]).T\n",
    "    family_household_income_transposed.columns = family_household_income_transposed.iloc[0]\n",
    "    family_household_income_transposed = family_household_income_transposed[1:]    \n",
    "    \n",
    "    nonfamily_household_income_transposed = nonfamily_household_income.filter([\"variables\", \"sum_in_area\"]).T\n",
    "    nonfamily_household_income_transposed.columns = nonfamily_household_income_transposed.iloc[0]\n",
    "    nonfamily_household_income_transposed = nonfamily_household_income_transposed[1:]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_range_for_each_variable():\n",
    "    \n",
    "    global range_table, range_table_all, ranges, first_range, other_ranges\n",
    "    transposed = [education_transposed, family_household_income_transposed, household_type_transposed, \\\n",
    "            language_transposed, nonfamily_household_income_transposed]\n",
    "    data.sort_values(by=['variable_group', 'sum_in_area'], ascending=[True, True], inplace=True)\n",
    "    data_sorted = data.reset_index()\n",
    "    \n",
    "    ranges=[]\n",
    "    \n",
    "    for df in transposed:\n",
    "        for item, i in enumerate(df.columns):\n",
    "            if item == 0:\n",
    "                first_range = np.arange(df.max()[item]+1).astype(int)\n",
    "                ranges.append([first_range])\n",
    "            else:\n",
    "                other_ranges = np.arange(df.min()[item-1]+1, \\\n",
    "                                       df.max()[item]+1).astype(int)\n",
    "                ranges.append([other_ranges])\n",
    "\n",
    "            range_table = pd.DataFrame(data=ranges, index=None, columns=[\"range_per_variable\"])\n",
    "            range_table = range_table.reset_index(drop=True)\n",
    "\n",
    "    range_table_all = pd.merge(range_table, data_sorted, left_index=True, right_index=True, on=None)\n",
    "    range_table_all[\"range_per_variable\"] = range_table_all[\"range_per_variable\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_info_for_text(): \n",
    "    \n",
    "    global result_df\n",
    "    \n",
    "    result_df = pd.DataFrame(columns=None)\n",
    "    for i in range_table_all['range_per_variable']:\n",
    "        if '\\n' in range_table_all:\n",
    "            range_table_all['range_per_variable'].replace(r'\\s+|\\\\n', ' ', regex=True, inplace=True) \n",
    "            \n",
    "    sum_for_percentile_language = language.sum_in_area.quantile(selected_percentile.value / 100).astype(int).astype(str)\n",
    "    sum_for_percentile_education = education.sum_in_area.quantile(selected_percentile.value / 100).astype(int).astype(str)\n",
    "    sum_for_percentile_family_household_income = family_household_income.sum_in_area.quantile(selected_percentile.value / 100).astype(int).astype(str)\n",
    "    sum_for_percentile_nonfamily_household_income = nonfamily_household_income.sum_in_area.quantile(selected_percentile.value / 100).astype(int).astype(str)\n",
    "    sum_for_percentile_household_type = household_type.sum_in_area.quantile(selected_percentile.value / 100).astype(int).astype(str)\n",
    "    \n",
    "    for item,i in enumerate(range_table_all.index):\n",
    "        if sum_for_percentile_education.astype(int) > 0 :\n",
    "            education_only = range_table_all[(range_table_all[\"variable_group\"].str.contains('Educational'))]\n",
    "            result = education_only[education_only[\"range_per_variable\"].str.contains(sum_for_percentile_education)]\n",
    "            result_df = result_df.append(result, ignore_index = True)\n",
    "\n",
    "        if sum_for_percentile_language.astype(int) > 0 :\n",
    "            language_only = range_table_all[(range_table_all[\"variable_group\"].str.contains('Language'))]\n",
    "            result = language_only[language_only[\"range_per_variable\"].str.contains(sum_for_percentile_language)]\n",
    "            result_df = result_df.append(result, ignore_index = True)\n",
    "\n",
    "        if sum_for_percentile_household_type.astype(int) > 0:\n",
    "            household_type_only = range_table_all[(range_table_all[\"variable_group\"].str.contains('Households'))]\n",
    "            result = household_type_only[household_type_only[\"range_per_variable\"].str.contains(sum_for_percentile_household_type)]\n",
    "            result_df = result_df.append(result, ignore_index = True)\n",
    "\n",
    "        if sum_for_percentile_family_household_income.astype(int) > 0:\n",
    "            family_household_income_only = range_table_all[(range_table_all[\"variable_group\"].str.contains('Family'))]\n",
    "            result = family_household_income_only[family_household_income_only[\"range_per_variable\"].str.contains(sum_for_percentile_family_household_income)]\n",
    "            result_df = result_df.append(result, ignore_index = True)\n",
    "\n",
    "        if sum_for_percentile_nonfamily_household_income.astype(int) > 0:\n",
    "            nonfamily_household_income_only = range_table_all[(range_table_all[\"variable_group\"].str.contains('Nonfamily'))]\n",
    "            result = nonfamily_household_income_only[nonfamily_household_income_only[\"range_per_variable\"].str.contains(sum_for_percentile_nonfamily_household_income)]\n",
    "            result_df = result_df.append(result, ignore_index = True)\n",
    "            \n",
    "    result_df = result_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_google_data():\n",
    "    extract_location()\n",
    "\n",
    "    keys_file = open(\"gcs_key.txt\")\n",
    "    APIKEY = keys_file.read().strip()\n",
    "    \n",
    "    global total_results\n",
    "    total_results = []\n",
    "    types = [\"bar\",\"cafe\",\"restaurant\"]\n",
    "\n",
    "    for i in types:\n",
    "        def findPlaces(pagetoken = None):\n",
    "            global lat, lon\n",
    "            lat, lng = (lat,lon)\n",
    "            radius=402\n",
    "            \n",
    "            url = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json?location={lat},{lng}&radius={radius}&fields=name,geometry,types,price_level&type={type}&key={APIKEY}{pagetoken}\".format(lat = lat, lng = lng, radius = radius, type = type,APIKEY = APIKEY, pagetoken = \"&pagetoken=\"+pagetoken if pagetoken else \"\")\n",
    "            response = requests.get(url)\n",
    "            res = json.loads(response.text)\n",
    "#             print(\"here results ---->>> \", len(res[\"results\"]))\n",
    "\n",
    "            for result in res[\"results\"]:\n",
    "                place_name = result['name']\n",
    "                latitude = result[\"geometry\"][\"location\"][\"lat\"]\n",
    "                longitude = result[\"geometry\"][\"location\"][\"lng\"]\n",
    "                place_type = result.get(\"types\",0)\n",
    "                price_level = result.get(\"price_level\",0)\n",
    "                total_results.append([latitude, longitude, place_name,place_type,price_level])\n",
    "\n",
    "            pagetoken = res.get(\"next_page_token\",None)\n",
    "\n",
    "#             print(\"here -->> \", pagetoken)\n",
    "\n",
    "            return pagetoken\n",
    "\n",
    "        pagetoken = None\n",
    "\n",
    "        while True:\n",
    "             pagetoken = findPlaces(pagetoken=pagetoken)\n",
    "             import time\n",
    "             time.sleep(5)\n",
    "\n",
    "             if not pagetoken:\n",
    "                 break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_google_data_for_text():\n",
    "    import_google_data()\n",
    "    \n",
    "    global places_df, establishment, price_range, list_ranges, very_expensive, expensive, moderately_priced, cheap, num_very_expensive, num_expensive, num_moderately_priced, num_cheap\n",
    "    places_df = pd.DataFrame(data=total_results, columns =[\"latitude\", \"longitude\", \"place_name\",\"place_type\",\"price_level\"]) \n",
    "    \n",
    "    very_expensive = places_df[((places_df[\"price_level\"]).astype(str).str.contains('4'))]\n",
    "    expensive = places_df[((places_df[\"price_level\"]).astype(str).str.contains('3'))]\n",
    "    moderately_priced = places_df[((places_df[\"price_level\"]).astype(str).str.contains('2'))]\n",
    "    cheap = places_df[((places_df[\"price_level\"]).astype(str).str.contains('1'))]\n",
    "    \n",
    "    num_very_expensive = len(very_expensive)\n",
    "    num_expensive = len(expensive)\n",
    "    num_moderately_priced = len(moderately_priced)\n",
    "    num_cheap = len(cheap)\n",
    "    \n",
    "    list_ranges = [num_very_expensive, num_expensive, num_moderately_priced, num_cheap]\n",
    "    \n",
    "    for i in places_df['price_level']:\n",
    "        if max(list_ranges) == num_very_expensive:\n",
    "            price_range = \", are very expensive.\"\n",
    "            establishment = random.choice(very_expensive[\"place_name\"].values) \n",
    "\n",
    "        if max(list_ranges) == num_expensive:\n",
    "            price_range = \", are expensive.\"\n",
    "            establishment = random.choice(expensive[\"place_name\"].values) \n",
    "\n",
    "        if max(list_ranges) == num_moderately_priced:\n",
    "            price_range = \", are moderately expensive.\"\n",
    "            establishment = random.choice(moderately_priced[\"place_name\"].values) \n",
    "\n",
    "        if max(list_ranges) == num_cheap:\n",
    "            price_range = \", are quite inexpensive.\"\n",
    "            establishment = random.choice(cheap[\"place_name\"].values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = widgets.Output()\n",
    "data_output = widgets.Output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_narrative():\n",
    "    \n",
    "    clean_combine_census_and_geographic_data()\n",
    "\n",
    "    selected_age.observe(selected_age_eventhandler, names='value')\n",
    "    selected_gender.observe(selected_gender_eventhandler, names='value')\n",
    "    selected_percentile.observe(selected_percentile_eventhandler, names='value')\n",
    "    \n",
    "    get_demographics_for_selection()\n",
    "    parse_tables_for_percentile_value()\n",
    "    get_range_for_each_variable()\n",
    "    generate_info_for_text()\n",
    "    generate_google_data_for_text()\n",
    "    \n",
    "    global result_df, resident_text, percentile_text, income_range, gender_text, subject_text, age_text,\\\n",
    "            household_type_text, income_text, language_text, education_text, resident_text_string,\\\n",
    "            establishment, price_range, price_experience, price_marker\n",
    "    \n",
    "    percentile_text = \" is representative of the top \"+ str(selected_percentile.value) + \"% of this area's residents. \"\n",
    "\n",
    "    if (selected_gender.value == \"Female\"):\n",
    "        gender_text = \"she\"\n",
    "        subject_text = \"woman\"\n",
    "        if (selected_age.value >= 5) & (selected_age.value <= 17):\n",
    "                subject_text = \"girl\"               \n",
    "    elif (selected_gender.value == \"Male\"):\n",
    "        gender_text = \"he\"\n",
    "        subject_text = \"man\"\n",
    "        if (selected_age.value >= 5) & (selected_age.value <= 17):\n",
    "            subject_text = \"boy\"\n",
    "    elif (selected_gender.value == \"ALL\"):\n",
    "        gender_text = \"he or she\"\n",
    "        subject_text = \"person\"\n",
    "        \n",
    "    if (selected_age.value >= 5) & (selected_age.value <= 12):\n",
    "        age_text = ''\n",
    "        age_text = age_text.replace(age_text, age_text)\n",
    "    elif (selected_age.value >= 13 ) & (selected_age.value <= 17):\n",
    "        age_text = 'teenage'\n",
    "        age_text = age_text.replace(age_text, age_text)\n",
    "    elif (selected_age.value >= 18 ) & (selected_age.value <= 34):\n",
    "        age_text = 'young'        \n",
    "        age_text = age_text.replace(age_text, age_text)\n",
    "    elif (selected_age.value >= 35 ) & (selected_age.value <= 64):\n",
    "        age_text = 'middle-aged'        \n",
    "        age_text = age_text.replace(age_text, age_text)\n",
    "    elif (selected_age.value >= 65 ):\n",
    "        age_text = 'senior'        \n",
    "        age_text = age_text.replace(age_text, age_text)\n",
    "        \n",
    "    for i in result_df['variable_name']:\n",
    "        if 'English' in i:\n",
    "            language_text = gender_text.capitalize() + \" speaks only English at home.\"\n",
    "        if 'Spanish' in i:\n",
    "            language_text = \"In addition to English, \" + gender_text + \" speaks Spanish at home.\"\n",
    "        if 'Indo-European' in i:\n",
    "            language_text = \"In addition to English, \" + gender_text + \" speaks an Indo-European language at home.\"            \n",
    "        if 'Asian' in i:\n",
    "            language_text = \"In addition to English, \" + gender_text + \" speaks an Asian or Pacific Island language at home.\"            \n",
    "        if 'Other languages' in i:\n",
    "            language_text = \"In addition to English, \" + gender_text + \" speaks other languages at home.\"\n",
    "\n",
    "        if 'Less than high school graduate' in i:\n",
    "            education_text = gender_text.capitalize() + ' does not have a high school degree.'\n",
    "        if 'High school graduate (includes equivalency)' in i:\n",
    "            education_text = gender_text.capitalize() + ' is a high school graduate.'\n",
    "        if 'Some college' in i:\n",
    "            education_text = gender_text.capitalize() + ' has attended some form of college but does not have a degree.'\n",
    "        if 'Bachelor' in i:\n",
    "            education_text = gender_text.capitalize() + \" is well-educated and has at least a bachelor's degree.\"\n",
    "        else:\n",
    "            education_text = ''\n",
    "\n",
    "        if 'Nonfamily Household Income In ' in i:\n",
    "            household_type_text = ' household consisting of non-family members'\n",
    "            result_df=result_df.loc[~result_df[\"variable_name\"].str.contains('Family Household Income')]\n",
    "        elif 'Family Household Income In ' in i:\n",
    "            result_df=result_df.loc[~result_df[\"variable_name\"].str.contains('Nonfamily Household Income')]\n",
    "            household_type_text = ' household consisting of family members'\n",
    "        else: \n",
    "            household_type_text=' household '\n",
    "\n",
    "        if '10,999' or '14,999' in i:\n",
    "            income_text = \" lower income\"\n",
    "            for i in places_df['price_level']:\n",
    "                if (max(list_ranges) == num_very_expensive) | (max(list_ranges) == num_expensive):\n",
    "                    price_marker = \"prohibitively expensive\"\n",
    "                elif max(list_ranges) == num_moderately_priced:\n",
    "                    price_marker = \"expensive\"\n",
    "                elif max(list_ranges) == num_cheap:\n",
    "                    price_marker = \"affordable\"\n",
    "        if '24,999' or '34,999' or '49,999' in i:\n",
    "            income_text = \" middle income\"\n",
    "            for i in places_df['price_level']:\n",
    "                if max(list_ranges) == num_very_expensive:\n",
    "                    price_marker = \"prohibitively expensive\"\n",
    "                elif max(list_ranges) == num_expensive:\n",
    "                    price_marker = \"expensive\"\n",
    "                elif (max(list_ranges) == num_cheap) | (max(list_ranges) == num_moderately_priced):\n",
    "                    price_marker = \"affordable\"\n",
    "        if '74,999' or '94,999' or '149,999' in i:\n",
    "            income_text = \" wealthy\"\n",
    "            for i in places_df['price_level']:\n",
    "                if max(list_ranges) == num_very_expensive:\n",
    "                    price_marker = \"expensive\"                \n",
    "                elif (max(list_ranges) == num_cheap) | (max(list_ranges) == num_moderately_priced) | (max(list_ranges) == num_expensive):\n",
    "                    price_marker = \"affordable\"\n",
    "        if '199,999' or '200,000' in i:\n",
    "            income_text = \" very wealthy\"\n",
    "            price_marker = \"affordable\"\n",
    "\n",
    "        income = result_df.loc[result_df[\"variable_name\"].str.contains('Income')]\n",
    "        income_range = income[\"variable_name\"].str.split('$').str[1]\n",
    "    \n",
    "    price_text = \" Most of the eating and drinking establishments in this area, such as \" + establishment + price_range\n",
    "    price_experience = \" Given this \" + subject_text +\"'s income, these restaurants, bars and cafes would be \" + price_marker + \". \"\n",
    "\n",
    "    resident_text = \"This \" + age_text + \" \" + subject_text + percentile_text + \\\n",
    "                    gender_text.capitalize() + \" lives in a\" + income_text + household_type_text + \\\n",
    "                    \"with an income in the $\" + income_range + \" range. \" + \\\n",
    "                    language_text + \\\n",
    "                    education_text + \\\n",
    "                    price_text + price_experience\n",
    "    \n",
    "    resident_text_string = resident_text.values[0].strip('\"\\'')\n",
    "    \n",
    "    with output:\n",
    "        display(resident_text_string)\n",
    "\n",
    "construct_narrative()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generation_button = Button(description=\"GENERATE NARRATIVE\",\\\n",
    "                               layout=Layout(width='60%', height='50px', border='solid .5px #000'))\n",
    "text_generation_button.style.button_color = '#EDF9FC'\n",
    "text_generation_button.style.font_weight = 'bold'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEXT GENERATION\n",
    "def text_generation(b):\n",
    "    output.clear_output()\n",
    "    data_output.clear_output()\n",
    "    construct_narrative()   \n",
    "#     tab.layout.display = 'all'\n",
    "    show_dashboard()\n",
    "    \n",
    "text_generation_button.on_click(text_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59044637b9e64575b504cc1f04f1c78e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(BoundedIntText(value=25, description='AGE:', max=99, min=5), IntSlider(value=50,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046a1c1b2c874eab96eefba7bb627986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[40.754149260245406, -73.9823627471924], controls=(ZoomControl(options=['position', 'zoom_in_text',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_dashboard():\n",
    "    output.clear_output()\n",
    "    data_output.clear_output()\n",
    "    \n",
    "    item_layout = widgets.Layout(margin='0 0 10px 0', align_items='stretch')\n",
    "    item_layout_tab = widgets.Layout(margin='0 0 10px 0')\n",
    "    \n",
    "    explore_data = range_table_all.filter(['sum_in_area', 'sex',\\\n",
    "       'age_group', 'variable_group', 'variable_name'])\n",
    "    explore_data['sum_in_area'] = explore_data['sum_in_area'].astype(int)\n",
    "    \n",
    "    with output:\n",
    "        display(md(\"> <font size = 3, font color = black> {}\".format(resident_text_string)))\n",
    "#         display(md(\"*{resident_text.values[0]}*\"))\n",
    "#         display(resident_text.values[0])\n",
    "    with data_output:\n",
    "        display(explore_data)\n",
    "    \n",
    "    global tab, input_widgets\n",
    "    input_widgets = widgets.VBox(\n",
    "        [selected_age, selected_percentile, selected_gender, text_generation_button],\n",
    "        layout=item_layout)\n",
    "    \n",
    "    tab = widgets.Tab([output, data_output],\n",
    "        layout=item_layout_tab)\n",
    "#     tab.layout.display = 'all'\n",
    "    tab.set_title(0, 'Narrative')\n",
    "    tab.set_title(1, 'Dataset')\n",
    "    \n",
    "    global dashboard\n",
    "    dashboard = widgets.VBox([input_widgets, tab])\n",
    "\n",
    "show_dashboard()\n",
    "\n",
    "\n",
    "display(dashboard)\n",
    "m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
